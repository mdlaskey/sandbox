I1204 03:59:17.700011 1969066752 caffe.cpp:177] Use CPU.
I1204 03:59:17.999167 1969066752 solver.cpp:47] Initializing solver from parameters: 
test_iter: 1
test_interval: 1
base_lr: 0.001
display: 1
max_iter: 300
lr_policy: "step"
gamma: 0.001
momentum: 0.9
weight_decay: 0.0005
stepsize: 10
snapshot: 5
snapshot_prefix: "weights"
solver_mode: CPU
net: "/Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net4/trainer4.prototxt"
I1204 03:59:18.000283 1969066752 solver.cpp:90] Creating training net from net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net4/trainer4.prototxt
I1204 03:59:18.000578 1969066752 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1204 03:59:18.000603 1969066752 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt"
    batch_size: 450
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "tanhConv1"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "conv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "tanh"
  type: "TanH"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1204 03:59:18.000823 1969066752 layer_factory.hpp:76] Creating layer data
I1204 03:59:18.000862 1969066752 net.cpp:106] Creating Layer data
I1204 03:59:18.000885 1969066752 net.cpp:411] data -> data
I1204 03:59:18.000919 1969066752 net.cpp:411] data -> labels
I1204 03:59:18.000947 1969066752 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt
I1204 03:59:18.001037 1969066752 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1204 03:59:18.002125 1969066752 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1204 03:59:18.284963 1969066752 net.cpp:150] Setting up data
I1204 03:59:18.284988 1969066752 net.cpp:157] Top shape: 450 3 125 125 (21093750)
I1204 03:59:18.285004 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 03:59:18.285012 1969066752 net.cpp:165] Memory required for data: 84382200
I1204 03:59:18.285024 1969066752 layer_factory.hpp:76] Creating layer conv1
I1204 03:59:18.285044 1969066752 net.cpp:106] Creating Layer conv1
I1204 03:59:18.285056 1969066752 net.cpp:454] conv1 <- data
I1204 03:59:18.285073 1969066752 net.cpp:411] conv1 -> conv1
I1204 03:59:18.290056 1969066752 net.cpp:150] Setting up conv1
I1204 03:59:18.290072 1969066752 net.cpp:157] Top shape: 450 16 115 115 (95220000)
I1204 03:59:18.290079 1969066752 net.cpp:165] Memory required for data: 465262200
I1204 03:59:18.290115 1969066752 layer_factory.hpp:76] Creating layer tanhConv1
I1204 03:59:18.290179 1969066752 net.cpp:106] Creating Layer tanhConv1
I1204 03:59:18.290207 1969066752 net.cpp:454] tanhConv1 <- conv1
I1204 03:59:18.290230 1969066752 net.cpp:397] tanhConv1 -> conv1 (in-place)
I1204 03:59:18.290269 1969066752 net.cpp:150] Setting up tanhConv1
I1204 03:59:18.290300 1969066752 net.cpp:157] Top shape: 450 16 115 115 (95220000)
I1204 03:59:18.290314 1969066752 net.cpp:165] Memory required for data: 846142200
I1204 03:59:18.290333 1969066752 layer_factory.hpp:76] Creating layer conv2
I1204 03:59:18.290377 1969066752 net.cpp:106] Creating Layer conv2
I1204 03:59:18.290391 1969066752 net.cpp:454] conv2 <- conv1
I1204 03:59:18.290427 1969066752 net.cpp:411] conv2 -> conv2
I1204 03:59:18.290750 1969066752 net.cpp:150] Setting up conv2
I1204 03:59:18.290757 1969066752 net.cpp:157] Top shape: 450 16 53 53 (20224800)
I1204 03:59:18.290762 1969066752 net.cpp:165] Memory required for data: 927041400
I1204 03:59:18.290769 1969066752 layer_factory.hpp:76] Creating layer reluConv2
I1204 03:59:18.290778 1969066752 net.cpp:106] Creating Layer reluConv2
I1204 03:59:18.290822 1969066752 net.cpp:454] reluConv2 <- conv2
I1204 03:59:18.290843 1969066752 net.cpp:397] reluConv2 -> conv2 (in-place)
I1204 03:59:18.290868 1969066752 net.cpp:150] Setting up reluConv2
I1204 03:59:18.290885 1969066752 net.cpp:157] Top shape: 450 16 53 53 (20224800)
I1204 03:59:18.290901 1969066752 net.cpp:165] Memory required for data: 1007940600
I1204 03:59:18.290935 1969066752 layer_factory.hpp:76] Creating layer fc1
I1204 03:59:18.291970 1969066752 net.cpp:106] Creating Layer fc1
I1204 03:59:18.291991 1969066752 net.cpp:454] fc1 <- conv2
I1204 03:59:18.292033 1969066752 net.cpp:411] fc1 -> fc1
I1204 03:59:18.311323 1969066752 net.cpp:150] Setting up fc1
I1204 03:59:18.311344 1969066752 net.cpp:157] Top shape: 450 40 (18000)
I1204 03:59:18.311350 1969066752 net.cpp:165] Memory required for data: 1008012600
I1204 03:59:18.311360 1969066752 layer_factory.hpp:76] Creating layer tanh
I1204 03:59:18.311368 1969066752 net.cpp:106] Creating Layer tanh
I1204 03:59:18.311373 1969066752 net.cpp:454] tanh <- fc1
I1204 03:59:18.311403 1969066752 net.cpp:397] tanh -> fc1 (in-place)
I1204 03:59:18.311465 1969066752 net.cpp:150] Setting up tanh
I1204 03:59:18.311485 1969066752 net.cpp:157] Top shape: 450 40 (18000)
I1204 03:59:18.311502 1969066752 net.cpp:165] Memory required for data: 1008084600
I1204 03:59:18.311527 1969066752 layer_factory.hpp:76] Creating layer fc2
I1204 03:59:18.311564 1969066752 net.cpp:106] Creating Layer fc2
I1204 03:59:18.311592 1969066752 net.cpp:454] fc2 <- fc1
I1204 03:59:18.311635 1969066752 net.cpp:411] fc2 -> fc2
I1204 03:59:18.311671 1969066752 net.cpp:150] Setting up fc2
I1204 03:59:18.311700 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 03:59:18.311740 1969066752 net.cpp:165] Memory required for data: 1008091800
I1204 03:59:18.311770 1969066752 layer_factory.hpp:76] Creating layer out
I1204 03:59:18.311795 1969066752 net.cpp:106] Creating Layer out
I1204 03:59:18.311816 1969066752 net.cpp:454] out <- fc2
I1204 03:59:18.311841 1969066752 net.cpp:411] out -> out
I1204 03:59:18.311873 1969066752 net.cpp:150] Setting up out
I1204 03:59:18.311907 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 03:59:18.311934 1969066752 net.cpp:165] Memory required for data: 1008099000
I1204 03:59:18.311962 1969066752 layer_factory.hpp:76] Creating layer loss
I1204 03:59:18.311983 1969066752 net.cpp:106] Creating Layer loss
I1204 03:59:18.312000 1969066752 net.cpp:454] loss <- out
I1204 03:59:18.312021 1969066752 net.cpp:454] loss <- labels
I1204 03:59:18.312031 1969066752 net.cpp:411] loss -> loss
I1204 03:59:18.312044 1969066752 net.cpp:150] Setting up loss
I1204 03:59:18.312048 1969066752 net.cpp:157] Top shape: (1)
I1204 03:59:18.312052 1969066752 net.cpp:160]     with loss weight 1
I1204 03:59:18.312062 1969066752 net.cpp:165] Memory required for data: 1008099004
I1204 03:59:18.312067 1969066752 net.cpp:226] loss needs backward computation.
I1204 03:59:18.312124 1969066752 net.cpp:226] out needs backward computation.
I1204 03:59:18.312146 1969066752 net.cpp:226] fc2 needs backward computation.
I1204 03:59:18.312165 1969066752 net.cpp:226] tanh needs backward computation.
I1204 03:59:18.312196 1969066752 net.cpp:226] fc1 needs backward computation.
I1204 03:59:18.312214 1969066752 net.cpp:226] reluConv2 needs backward computation.
I1204 03:59:18.312227 1969066752 net.cpp:226] conv2 needs backward computation.
I1204 03:59:18.312239 1969066752 net.cpp:226] tanhConv1 needs backward computation.
I1204 03:59:18.312249 1969066752 net.cpp:226] conv1 needs backward computation.
I1204 03:59:18.312257 1969066752 net.cpp:228] data does not need backward computation.
I1204 03:59:18.312261 1969066752 net.cpp:270] This network produces output loss
I1204 03:59:18.312271 1969066752 net.cpp:283] Network initialization done.
I1204 03:59:18.312537 1969066752 solver.cpp:180] Creating test net (#0) specified by net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net4/trainer4.prototxt
I1204 03:59:18.312566 1969066752 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1204 03:59:18.312621 1969066752 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt"
    batch_size: 120
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "tanhConv1"
  type: "TanH"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "conv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "tanh"
  type: "TanH"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1204 03:59:18.312782 1969066752 layer_factory.hpp:76] Creating layer data
I1204 03:59:18.312808 1969066752 net.cpp:106] Creating Layer data
I1204 03:59:18.312829 1969066752 net.cpp:411] data -> data
I1204 03:59:18.312850 1969066752 net.cpp:411] data -> labels
I1204 03:59:18.312871 1969066752 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt
I1204 03:59:18.312911 1969066752 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1204 03:59:18.393980 1969066752 net.cpp:150] Setting up data
I1204 03:59:18.394016 1969066752 net.cpp:157] Top shape: 120 3 125 125 (5625000)
I1204 03:59:18.394026 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 03:59:18.394031 1969066752 net.cpp:165] Memory required for data: 22501920
I1204 03:59:18.394141 1969066752 layer_factory.hpp:76] Creating layer conv1
I1204 03:59:18.394173 1969066752 net.cpp:106] Creating Layer conv1
I1204 03:59:18.394193 1969066752 net.cpp:454] conv1 <- data
I1204 03:59:18.394224 1969066752 net.cpp:411] conv1 -> conv1
I1204 03:59:18.394356 1969066752 net.cpp:150] Setting up conv1
I1204 03:59:18.394369 1969066752 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1204 03:59:18.394387 1969066752 net.cpp:165] Memory required for data: 124069920
I1204 03:59:18.394443 1969066752 layer_factory.hpp:76] Creating layer tanhConv1
I1204 03:59:18.394479 1969066752 net.cpp:106] Creating Layer tanhConv1
I1204 03:59:18.394513 1969066752 net.cpp:454] tanhConv1 <- conv1
I1204 03:59:18.394534 1969066752 net.cpp:397] tanhConv1 -> conv1 (in-place)
I1204 03:59:18.394598 1969066752 net.cpp:150] Setting up tanhConv1
I1204 03:59:18.394630 1969066752 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1204 03:59:18.394652 1969066752 net.cpp:165] Memory required for data: 225637920
I1204 03:59:18.394683 1969066752 layer_factory.hpp:76] Creating layer conv2
I1204 03:59:18.394717 1969066752 net.cpp:106] Creating Layer conv2
I1204 03:59:18.394733 1969066752 net.cpp:454] conv2 <- conv1
I1204 03:59:18.394752 1969066752 net.cpp:411] conv2 -> conv2
I1204 03:59:18.395131 1969066752 net.cpp:150] Setting up conv2
I1204 03:59:18.395141 1969066752 net.cpp:157] Top shape: 120 16 53 53 (5393280)
I1204 03:59:18.395146 1969066752 net.cpp:165] Memory required for data: 247211040
I1204 03:59:18.395154 1969066752 layer_factory.hpp:76] Creating layer reluConv2
I1204 03:59:18.395162 1969066752 net.cpp:106] Creating Layer reluConv2
I1204 03:59:18.395193 1969066752 net.cpp:454] reluConv2 <- conv2
I1204 03:59:18.395217 1969066752 net.cpp:397] reluConv2 -> conv2 (in-place)
I1204 03:59:18.395239 1969066752 net.cpp:150] Setting up reluConv2
I1204 03:59:18.395252 1969066752 net.cpp:157] Top shape: 120 16 53 53 (5393280)
I1204 03:59:18.395267 1969066752 net.cpp:165] Memory required for data: 268784160
I1204 03:59:18.395279 1969066752 layer_factory.hpp:76] Creating layer fc1
I1204 03:59:18.395292 1969066752 net.cpp:106] Creating Layer fc1
I1204 03:59:18.395299 1969066752 net.cpp:454] fc1 <- conv2
I1204 03:59:18.395329 1969066752 net.cpp:411] fc1 -> fc1
I1204 03:59:18.416102 1969066752 net.cpp:150] Setting up fc1
I1204 03:59:18.416121 1969066752 net.cpp:157] Top shape: 120 40 (4800)
I1204 03:59:18.416127 1969066752 net.cpp:165] Memory required for data: 268803360
I1204 03:59:18.416142 1969066752 layer_factory.hpp:76] Creating layer tanh
I1204 03:59:18.416152 1969066752 net.cpp:106] Creating Layer tanh
I1204 03:59:18.416184 1969066752 net.cpp:454] tanh <- fc1
I1204 03:59:18.416211 1969066752 net.cpp:397] tanh -> fc1 (in-place)
I1204 03:59:18.416245 1969066752 net.cpp:150] Setting up tanh
I1204 03:59:18.416267 1969066752 net.cpp:157] Top shape: 120 40 (4800)
I1204 03:59:18.416285 1969066752 net.cpp:165] Memory required for data: 268822560
I1204 03:59:18.416311 1969066752 layer_factory.hpp:76] Creating layer fc2
I1204 03:59:18.416327 1969066752 net.cpp:106] Creating Layer fc2
I1204 03:59:18.416337 1969066752 net.cpp:454] fc2 <- fc1
I1204 03:59:18.416347 1969066752 net.cpp:411] fc2 -> fc2
I1204 03:59:18.416373 1969066752 net.cpp:150] Setting up fc2
I1204 03:59:18.416380 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 03:59:18.416388 1969066752 net.cpp:165] Memory required for data: 268824480
I1204 03:59:18.416409 1969066752 layer_factory.hpp:76] Creating layer out
I1204 03:59:18.416452 1969066752 net.cpp:106] Creating Layer out
I1204 03:59:18.416470 1969066752 net.cpp:454] out <- fc2
I1204 03:59:18.416504 1969066752 net.cpp:411] out -> out
I1204 03:59:18.416543 1969066752 net.cpp:150] Setting up out
I1204 03:59:18.416576 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 03:59:18.416599 1969066752 net.cpp:165] Memory required for data: 268826400
I1204 03:59:18.416623 1969066752 layer_factory.hpp:76] Creating layer loss
I1204 03:59:18.416671 1969066752 net.cpp:106] Creating Layer loss
I1204 03:59:18.416697 1969066752 net.cpp:454] loss <- out
I1204 03:59:18.416746 1969066752 net.cpp:454] loss <- labels
I1204 03:59:18.416790 1969066752 net.cpp:411] loss -> loss
I1204 03:59:18.416828 1969066752 net.cpp:150] Setting up loss
I1204 03:59:18.416847 1969066752 net.cpp:157] Top shape: (1)
I1204 03:59:18.416872 1969066752 net.cpp:160]     with loss weight 1
I1204 03:59:18.416887 1969066752 net.cpp:165] Memory required for data: 268826404
I1204 03:59:18.416903 1969066752 net.cpp:226] loss needs backward computation.
I1204 03:59:18.416919 1969066752 net.cpp:226] out needs backward computation.
I1204 03:59:18.416954 1969066752 net.cpp:226] fc2 needs backward computation.
I1204 03:59:18.416980 1969066752 net.cpp:226] tanh needs backward computation.
I1204 03:59:18.416997 1969066752 net.cpp:226] fc1 needs backward computation.
I1204 03:59:18.417011 1969066752 net.cpp:226] reluConv2 needs backward computation.
I1204 03:59:18.417040 1969066752 net.cpp:226] conv2 needs backward computation.
I1204 03:59:18.417078 1969066752 net.cpp:226] tanhConv1 needs backward computation.
I1204 03:59:18.417098 1969066752 net.cpp:226] conv1 needs backward computation.
I1204 03:59:18.417122 1969066752 net.cpp:228] data does not need backward computation.
I1204 03:59:18.417147 1969066752 net.cpp:270] This network produces output loss
I1204 03:59:18.417173 1969066752 net.cpp:283] Network initialization done.
I1204 03:59:18.417265 1969066752 solver.cpp:59] Solver scaffolding done.
I1204 03:59:18.417322 1969066752 caffe.cpp:212] Starting Optimization
I1204 03:59:18.417359 1969066752 solver.cpp:287] Solving net
I1204 03:59:18.417378 1969066752 solver.cpp:288] Learning Rate Policy: step
I1204 03:59:18.423049 1969066752 solver.cpp:340] Iteration 0, Testing net (#0)
I1204 03:59:21.166635 1969066752 solver.cpp:408]     Test net output #0: loss = 0.311275 (* 1 = 0.311275 loss)
I1204 03:59:49.407836 1969066752 solver.cpp:236] Iteration 0, loss = 0.31095
I1204 03:59:49.407907 1969066752 solver.cpp:252]     Train net output #0: loss = 0.31095 (* 1 = 0.31095 loss)
I1204 03:59:49.407938 1969066752 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1204 03:59:49.417909 1969066752 solver.cpp:340] Iteration 1, Testing net (#0)
I1204 03:59:52.081161 1969066752 solver.cpp:408]     Test net output #0: loss = 0.235219 (* 1 = 0.235219 loss)
I1204 04:00:19.593166 1969066752 solver.cpp:236] Iteration 1, loss = 0.244608
I1204 04:00:19.593214 1969066752 solver.cpp:252]     Train net output #0: loss = 0.244608 (* 1 = 0.244608 loss)
I1204 04:00:19.593222 1969066752 sgd_solver.cpp:106] Iteration 1, lr = 0.001
I1204 04:00:19.599231 1969066752 solver.cpp:340] Iteration 2, Testing net (#0)
I1204 04:00:22.293314 1969066752 solver.cpp:408]     Test net output #0: loss = 0.248433 (* 1 = 0.248433 loss)
I1204 04:00:49.787216 1969066752 solver.cpp:236] Iteration 2, loss = 0.264384
I1204 04:00:49.787278 1969066752 solver.cpp:252]     Train net output #0: loss = 0.264384 (* 1 = 0.264384 loss)
I1204 04:00:49.787292 1969066752 sgd_solver.cpp:106] Iteration 2, lr = 0.001
I1204 04:00:49.792556 1969066752 solver.cpp:340] Iteration 3, Testing net (#0)
I1204 04:00:52.610440 1969066752 solver.cpp:408]     Test net output #0: loss = 0.251798 (* 1 = 0.251798 loss)
I1204 04:01:15.276412 1969066752 solver.cpp:236] Iteration 3, loss = 0.249481
I1204 04:01:15.276446 1969066752 solver.cpp:252]     Train net output #0: loss = 0.249481 (* 1 = 0.249481 loss)
I1204 04:01:15.276454 1969066752 sgd_solver.cpp:106] Iteration 3, lr = 0.001
I1204 04:01:15.282577 1969066752 solver.cpp:340] Iteration 4, Testing net (#0)
I1204 04:01:17.587070 1969066752 solver.cpp:408]     Test net output #0: loss = 0.208943 (* 1 = 0.208943 loss)
I1204 04:01:40.245671 1969066752 solver.cpp:236] Iteration 4, loss = 0.228462
I1204 04:01:40.245734 1969066752 solver.cpp:252]     Train net output #0: loss = 0.228462 (* 1 = 0.228462 loss)
I1204 04:01:40.245746 1969066752 sgd_solver.cpp:106] Iteration 4, lr = 0.001
I1204 04:01:40.249946 1969066752 solver.cpp:461] Snapshotting to binary proto file weights_iter_5.caffemodel
I1204 04:01:40.309546 1969066752 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_5.solverstate
I1204 04:01:40.346523 1969066752 solver.cpp:340] Iteration 5, Testing net (#0)
I1204 04:01:42.569665 1969066752 solver.cpp:408]     Test net output #0: loss = 0.212882 (* 1 = 0.212882 loss)
I1204 04:02:05.052872 1969066752 solver.cpp:236] Iteration 5, loss = 0.220459
I1204 04:02:05.052906 1969066752 solver.cpp:252]     Train net output #0: loss = 0.220459 (* 1 = 0.220459 loss)
I1204 04:02:05.052913 1969066752 sgd_solver.cpp:106] Iteration 5, lr = 0.001
I1204 04:02:05.057837 1969066752 solver.cpp:340] Iteration 6, Testing net (#0)
I1204 04:02:07.302989 1969066752 solver.cpp:408]     Test net output #0: loss = 0.233417 (* 1 = 0.233417 loss)
I1204 04:02:29.912889 1969066752 solver.cpp:236] Iteration 6, loss = 0.225703
I1204 04:02:29.913997 1969066752 solver.cpp:252]     Train net output #0: loss = 0.225703 (* 1 = 0.225703 loss)
I1204 04:02:29.914011 1969066752 sgd_solver.cpp:106] Iteration 6, lr = 0.001
I1204 04:02:29.918527 1969066752 solver.cpp:340] Iteration 7, Testing net (#0)
I1204 04:02:32.208427 1969066752 solver.cpp:408]     Test net output #0: loss = 0.201581 (* 1 = 0.201581 loss)
I1204 04:02:54.739449 1969066752 solver.cpp:236] Iteration 7, loss = 0.208765
I1204 04:02:54.739481 1969066752 solver.cpp:252]     Train net output #0: loss = 0.208765 (* 1 = 0.208765 loss)
I1204 04:02:54.739490 1969066752 sgd_solver.cpp:106] Iteration 7, lr = 0.001
I1204 04:02:54.743938 1969066752 solver.cpp:340] Iteration 8, Testing net (#0)
I1204 04:02:57.048599 1969066752 solver.cpp:408]     Test net output #0: loss = 0.176958 (* 1 = 0.176958 loss)
I1204 04:03:21.840361 1969066752 solver.cpp:236] Iteration 8, loss = 0.186289
I1204 04:03:21.840427 1969066752 solver.cpp:252]     Train net output #0: loss = 0.186289 (* 1 = 0.186289 loss)
I1204 04:03:21.840440 1969066752 sgd_solver.cpp:106] Iteration 8, lr = 0.001
I1204 04:03:21.845669 1969066752 solver.cpp:340] Iteration 9, Testing net (#0)
I1204 04:03:24.552888 1969066752 solver.cpp:408]     Test net output #0: loss = 0.189109 (* 1 = 0.189109 loss)
I1204 04:03:51.880156 1969066752 solver.cpp:236] Iteration 9, loss = 0.202227
I1204 04:03:51.880204 1969066752 solver.cpp:252]     Train net output #0: loss = 0.202227 (* 1 = 0.202227 loss)
I1204 04:03:51.880213 1969066752 sgd_solver.cpp:106] Iteration 9, lr = 0.001
I1204 04:03:51.886801 1969066752 solver.cpp:461] Snapshotting to binary proto file weights_iter_10.caffemodel
I1204 04:03:51.958609 1969066752 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_10.solverstate
I1204 04:03:52.002610 1969066752 solver.cpp:340] Iteration 10, Testing net (#0)
I1204 04:03:54.767572 1969066752 solver.cpp:408]     Test net output #0: loss = 0.18176 (* 1 = 0.18176 loss)
I1204 04:04:21.774673 1969066752 solver.cpp:236] Iteration 10, loss = 0.182743
I1204 04:04:21.774709 1969066752 solver.cpp:252]     Train net output #0: loss = 0.182743 (* 1 = 0.182743 loss)
I1204 04:04:21.774716 1969066752 sgd_solver.cpp:106] Iteration 10, lr = 1e-06
I1204 04:04:21.779863 1969066752 solver.cpp:340] Iteration 11, Testing net (#0)
I1204 04:04:24.563071 1969066752 solver.cpp:408]     Test net output #0: loss = 0.187997 (* 1 = 0.187997 loss)
I1204 04:04:52.553711 1969066752 solver.cpp:236] Iteration 11, loss = 0.208299
I1204 04:04:52.553750 1969066752 solver.cpp:252]     Train net output #0: loss = 0.208299 (* 1 = 0.208299 loss)
I1204 04:04:52.553757 1969066752 sgd_solver.cpp:106] Iteration 11, lr = 1e-06
I1204 04:04:52.560549 1969066752 solver.cpp:340] Iteration 12, Testing net (#0)
I1204 04:04:55.293900 1969066752 solver.cpp:408]     Test net output #0: loss = 0.190253 (* 1 = 0.190253 loss)
I1204 04:05:22.802567 1969066752 solver.cpp:236] Iteration 12, loss = 0.194576
I1204 04:05:22.802603 1969066752 solver.cpp:252]     Train net output #0: loss = 0.194576 (* 1 = 0.194576 loss)
I1204 04:05:22.802610 1969066752 sgd_solver.cpp:106] Iteration 12, lr = 1e-06
I1204 04:05:22.808732 1969066752 solver.cpp:340] Iteration 13, Testing net (#0)
I1204 04:05:25.756077 1969066752 solver.cpp:408]     Test net output #0: loss = 0.19377 (* 1 = 0.19377 loss)
I1204 04:05:53.836652 1969066752 solver.cpp:236] Iteration 13, loss = 0.213974
I1204 04:05:53.836688 1969066752 solver.cpp:252]     Train net output #0: loss = 0.213974 (* 1 = 0.213974 loss)
I1204 04:05:53.836695 1969066752 sgd_solver.cpp:106] Iteration 13, lr = 1e-06
I1204 04:05:53.841812 1969066752 solver.cpp:340] Iteration 14, Testing net (#0)
I1204 04:05:56.615646 1969066752 solver.cpp:408]     Test net output #0: loss = 0.201722 (* 1 = 0.201722 loss)
I1204 04:06:21.802381 1969066752 solver.cpp:236] Iteration 14, loss = 0.203108
I1204 04:06:21.802409 1969066752 solver.cpp:252]     Train net output #0: loss = 0.203108 (* 1 = 0.203108 loss)
I1204 04:06:21.802417 1969066752 sgd_solver.cpp:106] Iteration 14, lr = 1e-06
I1204 04:06:21.806741 1969066752 solver.cpp:461] Snapshotting to binary proto file weights_iter_15.caffemodel
I1204 04:06:21.867591 1969066752 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_15.solverstate
I1204 04:06:21.908007 1969066752 solver.cpp:340] Iteration 15, Testing net (#0)
I1204 04:06:24.217491 1969066752 solver.cpp:408]     Test net output #0: loss = 0.18514 (* 1 = 0.18514 loss)
I1204 04:06:48.235309 1969066752 solver.cpp:236] Iteration 15, loss = 0.223512
I1204 04:06:48.235357 1969066752 solver.cpp:252]     Train net output #0: loss = 0.223512 (* 1 = 0.223512 loss)
I1204 04:06:48.235365 1969066752 sgd_solver.cpp:106] Iteration 15, lr = 1e-06
I1204 04:06:48.241873 1969066752 solver.cpp:340] Iteration 16, Testing net (#0)
I1204 04:06:50.892292 1969066752 solver.cpp:408]     Test net output #0: loss = 0.216673 (* 1 = 0.216673 loss)
I1204 04:07:18.729084 1969066752 solver.cpp:236] Iteration 16, loss = 0.211655
I1204 04:07:18.729147 1969066752 solver.cpp:252]     Train net output #0: loss = 0.211655 (* 1 = 0.211655 loss)
I1204 04:07:18.729159 1969066752 sgd_solver.cpp:106] Iteration 16, lr = 1e-06
I1204 04:07:18.734469 1969066752 solver.cpp:340] Iteration 17, Testing net (#0)
I1204 04:07:21.446455 1969066752 solver.cpp:408]     Test net output #0: loss = 0.204581 (* 1 = 0.204581 loss)
I1204 04:07:46.119688 1969066752 solver.cpp:236] Iteration 17, loss = 0.222904
I1204 04:07:46.119720 1969066752 solver.cpp:252]     Train net output #0: loss = 0.222904 (* 1 = 0.222904 loss)
I1204 04:07:46.119727 1969066752 sgd_solver.cpp:106] Iteration 17, lr = 1e-06
I1204 04:07:46.124505 1969066752 solver.cpp:340] Iteration 18, Testing net (#0)
I1204 04:07:48.343073 1969066752 solver.cpp:408]     Test net output #0: loss = 0.215299 (* 1 = 0.215299 loss)
I1204 04:08:11.261328 1969066752 solver.cpp:236] Iteration 18, loss = 0.227361
I1204 04:08:11.261369 1969066752 solver.cpp:252]     Train net output #0: loss = 0.227361 (* 1 = 0.227361 loss)
I1204 04:08:11.261378 1969066752 sgd_solver.cpp:106] Iteration 18, lr = 1e-06
I1204 04:08:11.265728 1969066752 solver.cpp:340] Iteration 19, Testing net (#0)
I1204 04:08:13.583973 1969066752 solver.cpp:408]     Test net output #0: loss = 0.207835 (* 1 = 0.207835 loss)
I1204 04:08:40.446346 1969066752 solver.cpp:236] Iteration 19, loss = 0.219378
I1204 04:08:40.446382 1969066752 solver.cpp:252]     Train net output #0: loss = 0.219378 (* 1 = 0.219378 loss)
I1204 04:08:40.446389 1969066752 sgd_solver.cpp:106] Iteration 19, lr = 1e-06
I1204 04:08:40.451391 1969066752 solver.cpp:461] Snapshotting to binary proto file weights_iter_20.caffemodel
I1204 04:08:40.550413 1969066752 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_20.solverstate
I1204 04:08:40.623985 1969066752 solver.cpp:340] Iteration 20, Testing net (#0)
I1204 04:08:43.314223 1969066752 solver.cpp:408]     Test net output #0: loss = 0.212258 (* 1 = 0.212258 loss)
I1204 04:09:10.632441 1969066752 solver.cpp:236] Iteration 20, loss = 0.236546
I1204 04:09:10.632477 1969066752 solver.cpp:252]     Train net output #0: loss = 0.236546 (* 1 = 0.236546 loss)
I1204 04:09:10.632484 1969066752 sgd_solver.cpp:106] Iteration 20, lr = 1e-09
I1204 04:09:10.637989 1969066752 solver.cpp:340] Iteration 21, Testing net (#0)
I1204 04:09:13.342161 1969066752 solver.cpp:408]     Test net output #0: loss = 0.223472 (* 1 = 0.223472 loss)
