I1204 22:52:49.986937 1922425600 caffe.cpp:177] Use CPU.
I1204 22:52:50.522507 1922425600 solver.cpp:47] Initializing solver from parameters: 
test_iter: 1
test_interval: 1
base_lr: 0.01
display: 1
max_iter: 300
lr_policy: "step"
gamma: 0.1
stepsize: 150
snapshot: 5
snapshot_prefix: "weights"
solver_mode: CPU
net: "/Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net2/trainer2.prototxt"
I1204 22:52:50.522729 1922425600 solver.cpp:90] Creating training net from net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net2/trainer2.prototxt
I1204 22:52:50.522999 1922425600 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1204 22:52:50.523026 1922425600 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt"
    batch_size: 500
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv1"
  type: "ReLU"
  bottom: "conv1"
  top: "reluConv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "reluConv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv2"
  type: "ReLU"
  bottom: "conv2"
  top: "reluConv2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "reluConv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "fc1"
  top: "relu1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "relu1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1204 22:52:50.523203 1922425600 layer_factory.hpp:76] Creating layer data
I1204 22:52:50.523217 1922425600 net.cpp:106] Creating Layer data
I1204 22:52:50.523222 1922425600 net.cpp:411] data -> data
I1204 22:52:50.523239 1922425600 net.cpp:411] data -> labels
I1204 22:52:50.523250 1922425600 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt
I1204 22:52:50.523299 1922425600 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1204 22:52:50.524322 1922425600 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1204 22:52:50.706858 1922425600 net.cpp:150] Setting up data
I1204 22:52:50.706893 1922425600 net.cpp:157] Top shape: 500 3 125 125 (23437500)
I1204 22:52:50.706950 1922425600 net.cpp:157] Top shape: 500 4 (2000)
I1204 22:52:50.706972 1922425600 net.cpp:165] Memory required for data: 93758000
I1204 22:52:50.706982 1922425600 layer_factory.hpp:76] Creating layer conv1
I1204 22:52:50.706995 1922425600 net.cpp:106] Creating Layer conv1
I1204 22:52:50.707005 1922425600 net.cpp:454] conv1 <- data
I1204 22:52:50.707012 1922425600 net.cpp:411] conv1 -> conv1
I1204 22:52:50.711300 1922425600 net.cpp:150] Setting up conv1
I1204 22:52:50.711308 1922425600 net.cpp:157] Top shape: 500 16 115 115 (105800000)
I1204 22:52:50.711323 1922425600 net.cpp:165] Memory required for data: 516958000
I1204 22:52:50.711375 1922425600 layer_factory.hpp:76] Creating layer reluConv1
I1204 22:52:50.711395 1922425600 net.cpp:106] Creating Layer reluConv1
I1204 22:52:50.711398 1922425600 net.cpp:454] reluConv1 <- conv1
I1204 22:52:50.711403 1922425600 net.cpp:411] reluConv1 -> reluConv1
I1204 22:52:50.711410 1922425600 net.cpp:150] Setting up reluConv1
I1204 22:52:50.711415 1922425600 net.cpp:157] Top shape: 500 16 115 115 (105800000)
I1204 22:52:50.711419 1922425600 net.cpp:165] Memory required for data: 940158000
I1204 22:52:50.711423 1922425600 layer_factory.hpp:76] Creating layer conv2
I1204 22:52:50.711432 1922425600 net.cpp:106] Creating Layer conv2
I1204 22:52:50.711436 1922425600 net.cpp:454] conv2 <- reluConv1
I1204 22:52:50.711441 1922425600 net.cpp:411] conv2 -> conv2
I1204 22:52:50.711740 1922425600 net.cpp:150] Setting up conv2
I1204 22:52:50.711745 1922425600 net.cpp:157] Top shape: 500 16 53 53 (22472000)
I1204 22:52:50.711760 1922425600 net.cpp:165] Memory required for data: 1030046000
I1204 22:52:50.711766 1922425600 layer_factory.hpp:76] Creating layer reluConv2
I1204 22:52:50.711772 1922425600 net.cpp:106] Creating Layer reluConv2
I1204 22:52:50.711776 1922425600 net.cpp:454] reluConv2 <- conv2
I1204 22:52:50.711791 1922425600 net.cpp:411] reluConv2 -> reluConv2
I1204 22:52:50.711798 1922425600 net.cpp:150] Setting up reluConv2
I1204 22:52:50.711802 1922425600 net.cpp:157] Top shape: 500 16 53 53 (22472000)
I1204 22:52:50.711807 1922425600 net.cpp:165] Memory required for data: 1119934000
I1204 22:52:50.711809 1922425600 layer_factory.hpp:76] Creating layer fc1
I1204 22:52:50.711817 1922425600 net.cpp:106] Creating Layer fc1
I1204 22:52:50.711822 1922425600 net.cpp:454] fc1 <- reluConv2
I1204 22:52:50.711827 1922425600 net.cpp:411] fc1 -> fc1
I1204 22:52:50.726157 1922425600 net.cpp:150] Setting up fc1
I1204 22:52:50.726174 1922425600 net.cpp:157] Top shape: 500 40 (20000)
I1204 22:52:50.726189 1922425600 net.cpp:165] Memory required for data: 1120014000
I1204 22:52:50.726198 1922425600 layer_factory.hpp:76] Creating layer relu1
I1204 22:52:50.726207 1922425600 net.cpp:106] Creating Layer relu1
I1204 22:52:50.726210 1922425600 net.cpp:454] relu1 <- fc1
I1204 22:52:50.726217 1922425600 net.cpp:411] relu1 -> relu1
I1204 22:52:50.726234 1922425600 net.cpp:150] Setting up relu1
I1204 22:52:50.726238 1922425600 net.cpp:157] Top shape: 500 40 (20000)
I1204 22:52:50.726243 1922425600 net.cpp:165] Memory required for data: 1120094000
I1204 22:52:50.726245 1922425600 layer_factory.hpp:76] Creating layer fc2
I1204 22:52:50.726253 1922425600 net.cpp:106] Creating Layer fc2
I1204 22:52:50.726256 1922425600 net.cpp:454] fc2 <- relu1
I1204 22:52:50.726263 1922425600 net.cpp:411] fc2 -> fc2
I1204 22:52:50.726279 1922425600 net.cpp:150] Setting up fc2
I1204 22:52:50.726284 1922425600 net.cpp:157] Top shape: 500 4 (2000)
I1204 22:52:50.726296 1922425600 net.cpp:165] Memory required for data: 1120102000
I1204 22:52:50.726301 1922425600 layer_factory.hpp:76] Creating layer out
I1204 22:52:50.726317 1922425600 net.cpp:106] Creating Layer out
I1204 22:52:50.726321 1922425600 net.cpp:454] out <- fc2
I1204 22:52:50.726327 1922425600 net.cpp:411] out -> out
I1204 22:52:50.726333 1922425600 net.cpp:150] Setting up out
I1204 22:52:50.726336 1922425600 net.cpp:157] Top shape: 500 4 (2000)
I1204 22:52:50.726341 1922425600 net.cpp:165] Memory required for data: 1120110000
I1204 22:52:50.726344 1922425600 layer_factory.hpp:76] Creating layer loss
I1204 22:52:50.726351 1922425600 net.cpp:106] Creating Layer loss
I1204 22:52:50.726354 1922425600 net.cpp:454] loss <- out
I1204 22:52:50.726357 1922425600 net.cpp:454] loss <- labels
I1204 22:52:50.726362 1922425600 net.cpp:411] loss -> loss
I1204 22:52:50.726373 1922425600 net.cpp:150] Setting up loss
I1204 22:52:50.726377 1922425600 net.cpp:157] Top shape: (1)
I1204 22:52:50.726382 1922425600 net.cpp:160]     with loss weight 1
I1204 22:52:50.726413 1922425600 net.cpp:165] Memory required for data: 1120110004
I1204 22:52:50.726450 1922425600 net.cpp:226] loss needs backward computation.
I1204 22:52:50.726502 1922425600 net.cpp:226] out needs backward computation.
I1204 22:52:50.726506 1922425600 net.cpp:226] fc2 needs backward computation.
I1204 22:52:50.726511 1922425600 net.cpp:226] relu1 needs backward computation.
I1204 22:52:50.726513 1922425600 net.cpp:226] fc1 needs backward computation.
I1204 22:52:50.726517 1922425600 net.cpp:226] reluConv2 needs backward computation.
I1204 22:52:50.726521 1922425600 net.cpp:226] conv2 needs backward computation.
I1204 22:52:50.726526 1922425600 net.cpp:226] reluConv1 needs backward computation.
I1204 22:52:50.726531 1922425600 net.cpp:226] conv1 needs backward computation.
I1204 22:52:50.726537 1922425600 net.cpp:228] data does not need backward computation.
I1204 22:52:50.726542 1922425600 net.cpp:270] This network produces output loss
I1204 22:52:50.726553 1922425600 net.cpp:283] Network initialization done.
I1204 22:52:50.726819 1922425600 solver.cpp:180] Creating test net (#0) specified by net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net2/trainer2.prototxt
I1204 22:52:50.726855 1922425600 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1204 22:52:50.726876 1922425600 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt"
    batch_size: 120
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv1"
  type: "ReLU"
  bottom: "conv1"
  top: "reluConv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "reluConv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv2"
  type: "ReLU"
  bottom: "conv2"
  top: "reluConv2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "reluConv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "fc1"
  top: "relu1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "relu1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1204 22:52:50.727010 1922425600 layer_factory.hpp:76] Creating layer data
I1204 22:52:50.727016 1922425600 net.cpp:106] Creating Layer data
I1204 22:52:50.727021 1922425600 net.cpp:411] data -> data
I1204 22:52:50.727030 1922425600 net.cpp:411] data -> labels
I1204 22:52:50.727037 1922425600 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt
I1204 22:52:50.727077 1922425600 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1204 22:52:50.778934 1922425600 net.cpp:150] Setting up data
I1204 22:52:50.778959 1922425600 net.cpp:157] Top shape: 120 3 125 125 (5625000)
I1204 22:52:50.778966 1922425600 net.cpp:157] Top shape: 120 4 (480)
I1204 22:52:50.778971 1922425600 net.cpp:165] Memory required for data: 22501920
I1204 22:52:50.779011 1922425600 layer_factory.hpp:76] Creating layer conv1
I1204 22:52:50.779024 1922425600 net.cpp:106] Creating Layer conv1
I1204 22:52:50.779029 1922425600 net.cpp:454] conv1 <- data
I1204 22:52:50.779037 1922425600 net.cpp:411] conv1 -> conv1
I1204 22:52:50.779148 1922425600 net.cpp:150] Setting up conv1
I1204 22:52:50.779155 1922425600 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1204 22:52:50.779161 1922425600 net.cpp:165] Memory required for data: 124069920
I1204 22:52:50.779170 1922425600 layer_factory.hpp:76] Creating layer reluConv1
I1204 22:52:50.779176 1922425600 net.cpp:106] Creating Layer reluConv1
I1204 22:52:50.779181 1922425600 net.cpp:454] reluConv1 <- conv1
I1204 22:52:50.779186 1922425600 net.cpp:411] reluConv1 -> reluConv1
I1204 22:52:50.779196 1922425600 net.cpp:150] Setting up reluConv1
I1204 22:52:50.779201 1922425600 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1204 22:52:50.779219 1922425600 net.cpp:165] Memory required for data: 225637920
I1204 22:52:50.779232 1922425600 layer_factory.hpp:76] Creating layer conv2
I1204 22:52:50.779243 1922425600 net.cpp:106] Creating Layer conv2
I1204 22:52:50.779249 1922425600 net.cpp:454] conv2 <- reluConv1
I1204 22:52:50.779256 1922425600 net.cpp:411] conv2 -> conv2
I1204 22:52:50.779567 1922425600 net.cpp:150] Setting up conv2
I1204 22:52:50.779572 1922425600 net.cpp:157] Top shape: 120 16 53 53 (5393280)
I1204 22:52:50.779587 1922425600 net.cpp:165] Memory required for data: 247211040
I1204 22:52:50.779597 1922425600 layer_factory.hpp:76] Creating layer reluConv2
I1204 22:52:50.779603 1922425600 net.cpp:106] Creating Layer reluConv2
I1204 22:52:50.779616 1922425600 net.cpp:454] reluConv2 <- conv2
I1204 22:52:50.779621 1922425600 net.cpp:411] reluConv2 -> reluConv2
I1204 22:52:50.779628 1922425600 net.cpp:150] Setting up reluConv2
I1204 22:52:50.779638 1922425600 net.cpp:157] Top shape: 120 16 53 53 (5393280)
I1204 22:52:50.779642 1922425600 net.cpp:165] Memory required for data: 268784160
I1204 22:52:50.779646 1922425600 layer_factory.hpp:76] Creating layer fc1
I1204 22:52:50.779654 1922425600 net.cpp:106] Creating Layer fc1
I1204 22:52:50.779657 1922425600 net.cpp:454] fc1 <- reluConv2
I1204 22:52:50.779664 1922425600 net.cpp:411] fc1 -> fc1
I1204 22:52:50.793617 1922425600 net.cpp:150] Setting up fc1
I1204 22:52:50.793635 1922425600 net.cpp:157] Top shape: 120 40 (4800)
I1204 22:52:50.793650 1922425600 net.cpp:165] Memory required for data: 268803360
I1204 22:52:50.793660 1922425600 layer_factory.hpp:76] Creating layer relu1
I1204 22:52:50.793668 1922425600 net.cpp:106] Creating Layer relu1
I1204 22:52:50.793671 1922425600 net.cpp:454] relu1 <- fc1
I1204 22:52:50.793678 1922425600 net.cpp:411] relu1 -> relu1
I1204 22:52:50.793695 1922425600 net.cpp:150] Setting up relu1
I1204 22:52:50.793699 1922425600 net.cpp:157] Top shape: 120 40 (4800)
I1204 22:52:50.793704 1922425600 net.cpp:165] Memory required for data: 268822560
I1204 22:52:50.793707 1922425600 layer_factory.hpp:76] Creating layer fc2
I1204 22:52:50.793720 1922425600 net.cpp:106] Creating Layer fc2
I1204 22:52:50.793725 1922425600 net.cpp:454] fc2 <- relu1
I1204 22:52:50.793730 1922425600 net.cpp:411] fc2 -> fc2
I1204 22:52:50.793745 1922425600 net.cpp:150] Setting up fc2
I1204 22:52:50.793748 1922425600 net.cpp:157] Top shape: 120 4 (480)
I1204 22:52:50.793761 1922425600 net.cpp:165] Memory required for data: 268824480
I1204 22:52:50.793766 1922425600 layer_factory.hpp:76] Creating layer out
I1204 22:52:50.793784 1922425600 net.cpp:106] Creating Layer out
I1204 22:52:50.793788 1922425600 net.cpp:454] out <- fc2
I1204 22:52:50.793793 1922425600 net.cpp:411] out -> out
I1204 22:52:50.793798 1922425600 net.cpp:150] Setting up out
I1204 22:52:50.793802 1922425600 net.cpp:157] Top shape: 120 4 (480)
I1204 22:52:50.793807 1922425600 net.cpp:165] Memory required for data: 268826400
I1204 22:52:50.793810 1922425600 layer_factory.hpp:76] Creating layer loss
I1204 22:52:50.793817 1922425600 net.cpp:106] Creating Layer loss
I1204 22:52:50.793820 1922425600 net.cpp:454] loss <- out
I1204 22:52:50.793854 1922425600 net.cpp:454] loss <- labels
I1204 22:52:50.793869 1922425600 net.cpp:411] loss -> loss
I1204 22:52:50.793889 1922425600 net.cpp:150] Setting up loss
I1204 22:52:50.793891 1922425600 net.cpp:157] Top shape: (1)
I1204 22:52:50.793895 1922425600 net.cpp:160]     with loss weight 1
I1204 22:52:50.793903 1922425600 net.cpp:165] Memory required for data: 268826404
I1204 22:52:50.793907 1922425600 net.cpp:226] loss needs backward computation.
I1204 22:52:50.793911 1922425600 net.cpp:226] out needs backward computation.
I1204 22:52:50.793915 1922425600 net.cpp:226] fc2 needs backward computation.
I1204 22:52:50.793920 1922425600 net.cpp:226] relu1 needs backward computation.
I1204 22:52:50.793922 1922425600 net.cpp:226] fc1 needs backward computation.
I1204 22:52:50.793926 1922425600 net.cpp:226] reluConv2 needs backward computation.
I1204 22:52:50.793929 1922425600 net.cpp:226] conv2 needs backward computation.
I1204 22:52:50.793933 1922425600 net.cpp:226] reluConv1 needs backward computation.
I1204 22:52:50.793937 1922425600 net.cpp:226] conv1 needs backward computation.
I1204 22:52:50.793942 1922425600 net.cpp:228] data does not need backward computation.
I1204 22:52:50.793946 1922425600 net.cpp:270] This network produces output loss
I1204 22:52:50.793952 1922425600 net.cpp:283] Network initialization done.
I1204 22:52:50.793999 1922425600 solver.cpp:59] Solver scaffolding done.
I1204 22:52:50.794028 1922425600 caffe.cpp:212] Starting Optimization
I1204 22:52:50.794031 1922425600 solver.cpp:287] Solving net
I1204 22:52:50.794035 1922425600 solver.cpp:288] Learning Rate Policy: step
I1204 22:52:50.797025 1922425600 solver.cpp:340] Iteration 0, Testing net (#0)
I1204 22:52:52.783682 1922425600 solver.cpp:408]     Test net output #0: loss = 0.317661 (* 1 = 0.317661 loss)
I1204 22:53:15.665405 1922425600 solver.cpp:236] Iteration 0, loss = 0.350488
I1204 22:53:15.665433 1922425600 solver.cpp:252]     Train net output #0: loss = 0.350488 (* 1 = 0.350488 loss)
I1204 22:53:15.665455 1922425600 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1204 22:53:15.671636 1922425600 solver.cpp:340] Iteration 1, Testing net (#0)
I1204 22:53:17.614385 1922425600 solver.cpp:408]     Test net output #0: loss = 0.303721 (* 1 = 0.303721 loss)
I1204 22:53:39.476148 1922425600 solver.cpp:236] Iteration 1, loss = 0.324881
I1204 22:53:39.476189 1922425600 solver.cpp:252]     Train net output #0: loss = 0.324881 (* 1 = 0.324881 loss)
I1204 22:53:39.476197 1922425600 sgd_solver.cpp:106] Iteration 1, lr = 0.01
I1204 22:53:39.479457 1922425600 solver.cpp:340] Iteration 2, Testing net (#0)
I1204 22:53:41.420083 1922425600 solver.cpp:408]     Test net output #0: loss = 0.224365 (* 1 = 0.224365 loss)
I1204 22:54:03.189831 1922425600 solver.cpp:236] Iteration 2, loss = 0.228372
I1204 22:54:03.189860 1922425600 solver.cpp:252]     Train net output #0: loss = 0.228372 (* 1 = 0.228372 loss)
I1204 22:54:03.189868 1922425600 sgd_solver.cpp:106] Iteration 2, lr = 0.01
I1204 22:54:03.193094 1922425600 solver.cpp:340] Iteration 3, Testing net (#0)
I1204 22:54:05.100805 1922425600 solver.cpp:408]     Test net output #0: loss = 0.221789 (* 1 = 0.221789 loss)
I1204 22:54:27.669687 1922425600 solver.cpp:236] Iteration 3, loss = 0.21908
I1204 22:54:27.669725 1922425600 solver.cpp:252]     Train net output #0: loss = 0.21908 (* 1 = 0.21908 loss)
I1204 22:54:27.669734 1922425600 sgd_solver.cpp:106] Iteration 3, lr = 0.01
I1204 22:54:27.673015 1922425600 solver.cpp:340] Iteration 4, Testing net (#0)
I1204 22:54:29.574260 1922425600 solver.cpp:408]     Test net output #0: loss = 0.187898 (* 1 = 0.187898 loss)
I1204 22:54:51.457222 1922425600 solver.cpp:236] Iteration 4, loss = 0.213864
I1204 22:54:51.457250 1922425600 solver.cpp:252]     Train net output #0: loss = 0.213864 (* 1 = 0.213864 loss)
I1204 22:54:51.457257 1922425600 sgd_solver.cpp:106] Iteration 4, lr = 0.01
I1204 22:54:51.460464 1922425600 solver.cpp:461] Snapshotting to binary proto file weights_iter_5.caffemodel
I1204 22:54:51.532973 1922425600 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_5.solverstate
I1204 22:54:51.592602 1922425600 solver.cpp:340] Iteration 5, Testing net (#0)
I1204 22:54:53.553673 1922425600 solver.cpp:408]     Test net output #0: loss = 0.222635 (* 1 = 0.222635 loss)
