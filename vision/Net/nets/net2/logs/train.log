I1207 02:50:42.026034 2039878400 caffe.cpp:177] Use CPU.
I1207 02:50:42.588104 2039878400 solver.cpp:47] Initializing solver from parameters: 
test_iter: 1
test_interval: 1
base_lr: 0.01
display: 1
max_iter: 300
lr_policy: "step"
gamma: 0.1
stepsize: 150
snapshot: 5
snapshot_prefix: "weights"
solver_mode: CPU
net: "/Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net2/trainer2.prototxt"
I1207 02:50:42.588532 2039878400 solver.cpp:90] Creating training net from net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net2/trainer2.prototxt
I1207 02:50:42.588752 2039878400 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1207 02:50:42.588771 2039878400 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt"
    batch_size: 500
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv1"
  type: "ReLU"
  bottom: "conv1"
  top: "reluConv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "reluConv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv2"
  type: "ReLU"
  bottom: "conv2"
  top: "reluConv2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "reluConv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "fc1"
  top: "relu1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "relu1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1207 02:50:42.588894 2039878400 layer_factory.hpp:76] Creating layer data
I1207 02:50:42.588908 2039878400 net.cpp:106] Creating Layer data
I1207 02:50:42.588914 2039878400 net.cpp:411] data -> data
I1207 02:50:42.588937 2039878400 net.cpp:411] data -> labels
I1207 02:50:42.588949 2039878400 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt
I1207 02:50:42.588984 2039878400 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1207 02:50:42.590558 2039878400 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1207 02:50:43.113632 2039878400 net.cpp:150] Setting up data
I1207 02:50:43.113662 2039878400 net.cpp:157] Top shape: 500 3 125 125 (23437500)
I1207 02:50:43.113674 2039878400 net.cpp:157] Top shape: 500 4 (2000)
I1207 02:50:43.113680 2039878400 net.cpp:165] Memory required for data: 93758000
I1207 02:50:43.113689 2039878400 layer_factory.hpp:76] Creating layer conv1
I1207 02:50:43.113703 2039878400 net.cpp:106] Creating Layer conv1
I1207 02:50:43.113713 2039878400 net.cpp:454] conv1 <- data
I1207 02:50:43.113724 2039878400 net.cpp:411] conv1 -> conv1
I1207 02:50:43.118613 2039878400 net.cpp:150] Setting up conv1
I1207 02:50:43.118625 2039878400 net.cpp:157] Top shape: 500 16 115 115 (105800000)
I1207 02:50:43.118633 2039878400 net.cpp:165] Memory required for data: 516958000
I1207 02:50:43.118674 2039878400 layer_factory.hpp:76] Creating layer reluConv1
I1207 02:50:43.118685 2039878400 net.cpp:106] Creating Layer reluConv1
I1207 02:50:43.118690 2039878400 net.cpp:454] reluConv1 <- conv1
I1207 02:50:43.118696 2039878400 net.cpp:411] reluConv1 -> reluConv1
I1207 02:50:43.118726 2039878400 net.cpp:150] Setting up reluConv1
I1207 02:50:43.118736 2039878400 net.cpp:157] Top shape: 500 16 115 115 (105800000)
I1207 02:50:43.118743 2039878400 net.cpp:165] Memory required for data: 940158000
I1207 02:50:43.118747 2039878400 layer_factory.hpp:76] Creating layer conv2
I1207 02:50:43.118755 2039878400 net.cpp:106] Creating Layer conv2
I1207 02:50:43.118759 2039878400 net.cpp:454] conv2 <- reluConv1
I1207 02:50:43.118767 2039878400 net.cpp:411] conv2 -> conv2
I1207 02:50:43.119009 2039878400 net.cpp:150] Setting up conv2
I1207 02:50:43.119014 2039878400 net.cpp:157] Top shape: 500 16 53 53 (22472000)
I1207 02:50:43.119031 2039878400 net.cpp:165] Memory required for data: 1030046000
I1207 02:50:43.119043 2039878400 layer_factory.hpp:76] Creating layer reluConv2
I1207 02:50:43.119050 2039878400 net.cpp:106] Creating Layer reluConv2
I1207 02:50:43.119055 2039878400 net.cpp:454] reluConv2 <- conv2
I1207 02:50:43.119060 2039878400 net.cpp:411] reluConv2 -> reluConv2
I1207 02:50:43.119066 2039878400 net.cpp:150] Setting up reluConv2
I1207 02:50:43.119070 2039878400 net.cpp:157] Top shape: 500 16 53 53 (22472000)
I1207 02:50:43.119076 2039878400 net.cpp:165] Memory required for data: 1119934000
I1207 02:50:43.119081 2039878400 layer_factory.hpp:76] Creating layer fc1
I1207 02:50:43.119096 2039878400 net.cpp:106] Creating Layer fc1
I1207 02:50:43.119102 2039878400 net.cpp:454] fc1 <- reluConv2
I1207 02:50:43.119107 2039878400 net.cpp:411] fc1 -> fc1
I1207 02:50:43.133252 2039878400 net.cpp:150] Setting up fc1
I1207 02:50:43.133287 2039878400 net.cpp:157] Top shape: 500 40 (20000)
I1207 02:50:43.133293 2039878400 net.cpp:165] Memory required for data: 1120014000
I1207 02:50:43.133303 2039878400 layer_factory.hpp:76] Creating layer relu1
I1207 02:50:43.133313 2039878400 net.cpp:106] Creating Layer relu1
I1207 02:50:43.133317 2039878400 net.cpp:454] relu1 <- fc1
I1207 02:50:43.133334 2039878400 net.cpp:411] relu1 -> relu1
I1207 02:50:43.133347 2039878400 net.cpp:150] Setting up relu1
I1207 02:50:43.133350 2039878400 net.cpp:157] Top shape: 500 40 (20000)
I1207 02:50:43.133355 2039878400 net.cpp:165] Memory required for data: 1120094000
I1207 02:50:43.133359 2039878400 layer_factory.hpp:76] Creating layer fc2
I1207 02:50:43.133366 2039878400 net.cpp:106] Creating Layer fc2
I1207 02:50:43.133371 2039878400 net.cpp:454] fc2 <- relu1
I1207 02:50:43.133376 2039878400 net.cpp:411] fc2 -> fc2
I1207 02:50:43.133395 2039878400 net.cpp:150] Setting up fc2
I1207 02:50:43.133400 2039878400 net.cpp:157] Top shape: 500 4 (2000)
I1207 02:50:43.133405 2039878400 net.cpp:165] Memory required for data: 1120102000
I1207 02:50:43.133410 2039878400 layer_factory.hpp:76] Creating layer out
I1207 02:50:43.133416 2039878400 net.cpp:106] Creating Layer out
I1207 02:50:43.133420 2039878400 net.cpp:454] out <- fc2
I1207 02:50:43.133425 2039878400 net.cpp:411] out -> out
I1207 02:50:43.133432 2039878400 net.cpp:150] Setting up out
I1207 02:50:43.133436 2039878400 net.cpp:157] Top shape: 500 4 (2000)
I1207 02:50:43.133441 2039878400 net.cpp:165] Memory required for data: 1120110000
I1207 02:50:43.133445 2039878400 layer_factory.hpp:76] Creating layer loss
I1207 02:50:43.133451 2039878400 net.cpp:106] Creating Layer loss
I1207 02:50:43.133455 2039878400 net.cpp:454] loss <- out
I1207 02:50:43.133460 2039878400 net.cpp:454] loss <- labels
I1207 02:50:43.133465 2039878400 net.cpp:411] loss -> loss
I1207 02:50:43.133478 2039878400 net.cpp:150] Setting up loss
I1207 02:50:43.133482 2039878400 net.cpp:157] Top shape: (1)
I1207 02:50:43.133486 2039878400 net.cpp:160]     with loss weight 1
I1207 02:50:43.133519 2039878400 net.cpp:165] Memory required for data: 1120110004
I1207 02:50:43.133523 2039878400 net.cpp:226] loss needs backward computation.
I1207 02:50:43.133554 2039878400 net.cpp:226] out needs backward computation.
I1207 02:50:43.133559 2039878400 net.cpp:226] fc2 needs backward computation.
I1207 02:50:43.133563 2039878400 net.cpp:226] relu1 needs backward computation.
I1207 02:50:43.133566 2039878400 net.cpp:226] fc1 needs backward computation.
I1207 02:50:43.133570 2039878400 net.cpp:226] reluConv2 needs backward computation.
I1207 02:50:43.133574 2039878400 net.cpp:226] conv2 needs backward computation.
I1207 02:50:43.133577 2039878400 net.cpp:226] reluConv1 needs backward computation.
I1207 02:50:43.133581 2039878400 net.cpp:226] conv1 needs backward computation.
I1207 02:50:43.133585 2039878400 net.cpp:228] data does not need backward computation.
I1207 02:50:43.133589 2039878400 net.cpp:270] This network produces output loss
I1207 02:50:43.133595 2039878400 net.cpp:283] Network initialization done.
I1207 02:50:43.133851 2039878400 solver.cpp:180] Creating test net (#0) specified by net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net2/trainer2.prototxt
I1207 02:50:43.133883 2039878400 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1207 02:50:43.133904 2039878400 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt"
    batch_size: 120
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv1"
  type: "ReLU"
  bottom: "conv1"
  top: "reluConv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "reluConv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv2"
  type: "ReLU"
  bottom: "conv2"
  top: "reluConv2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "reluConv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "fc1"
  top: "relu1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "relu1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1207 02:50:43.134063 2039878400 layer_factory.hpp:76] Creating layer data
I1207 02:50:43.134070 2039878400 net.cpp:106] Creating Layer data
I1207 02:50:43.134086 2039878400 net.cpp:411] data -> data
I1207 02:50:43.134093 2039878400 net.cpp:411] data -> labels
I1207 02:50:43.134100 2039878400 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt
I1207 02:50:43.134124 2039878400 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1207 02:50:43.281301 2039878400 net.cpp:150] Setting up data
I1207 02:50:43.281324 2039878400 net.cpp:157] Top shape: 120 3 125 125 (5625000)
I1207 02:50:43.281333 2039878400 net.cpp:157] Top shape: 120 4 (480)
I1207 02:50:43.281338 2039878400 net.cpp:165] Memory required for data: 22501920
I1207 02:50:43.281366 2039878400 layer_factory.hpp:76] Creating layer conv1
I1207 02:50:43.281379 2039878400 net.cpp:106] Creating Layer conv1
I1207 02:50:43.281386 2039878400 net.cpp:454] conv1 <- data
I1207 02:50:43.281394 2039878400 net.cpp:411] conv1 -> conv1
I1207 02:50:43.281477 2039878400 net.cpp:150] Setting up conv1
I1207 02:50:43.281484 2039878400 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1207 02:50:43.281491 2039878400 net.cpp:165] Memory required for data: 124069920
I1207 02:50:43.281499 2039878400 layer_factory.hpp:76] Creating layer reluConv1
I1207 02:50:43.281507 2039878400 net.cpp:106] Creating Layer reluConv1
I1207 02:50:43.281510 2039878400 net.cpp:454] reluConv1 <- conv1
I1207 02:50:43.281520 2039878400 net.cpp:411] reluConv1 -> reluConv1
I1207 02:50:43.281533 2039878400 net.cpp:150] Setting up reluConv1
I1207 02:50:43.281538 2039878400 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1207 02:50:43.281544 2039878400 net.cpp:165] Memory required for data: 225637920
I1207 02:50:43.281548 2039878400 layer_factory.hpp:76] Creating layer conv2
I1207 02:50:43.281556 2039878400 net.cpp:106] Creating Layer conv2
I1207 02:50:43.281561 2039878400 net.cpp:454] conv2 <- reluConv1
I1207 02:50:43.281568 2039878400 net.cpp:411] conv2 -> conv2
I1207 02:50:43.281873 2039878400 net.cpp:150] Setting up conv2
I1207 02:50:43.281879 2039878400 net.cpp:157] Top shape: 120 16 53 53 (5393280)
I1207 02:50:43.281885 2039878400 net.cpp:165] Memory required for data: 247211040
I1207 02:50:43.281894 2039878400 layer_factory.hpp:76] Creating layer reluConv2
I1207 02:50:43.281901 2039878400 net.cpp:106] Creating Layer reluConv2
I1207 02:50:43.281905 2039878400 net.cpp:454] reluConv2 <- conv2
I1207 02:50:43.281911 2039878400 net.cpp:411] reluConv2 -> reluConv2
I1207 02:50:43.281919 2039878400 net.cpp:150] Setting up reluConv2
I1207 02:50:43.281924 2039878400 net.cpp:157] Top shape: 120 16 53 53 (5393280)
I1207 02:50:43.281929 2039878400 net.cpp:165] Memory required for data: 268784160
I1207 02:50:43.281932 2039878400 layer_factory.hpp:76] Creating layer fc1
I1207 02:50:43.281940 2039878400 net.cpp:106] Creating Layer fc1
I1207 02:50:43.281946 2039878400 net.cpp:454] fc1 <- reluConv2
I1207 02:50:43.281960 2039878400 net.cpp:411] fc1 -> fc1
I1207 02:50:43.296272 2039878400 net.cpp:150] Setting up fc1
I1207 02:50:43.296291 2039878400 net.cpp:157] Top shape: 120 40 (4800)
I1207 02:50:43.296296 2039878400 net.cpp:165] Memory required for data: 268803360
I1207 02:50:43.296306 2039878400 layer_factory.hpp:76] Creating layer relu1
I1207 02:50:43.296314 2039878400 net.cpp:106] Creating Layer relu1
I1207 02:50:43.296319 2039878400 net.cpp:454] relu1 <- fc1
I1207 02:50:43.296324 2039878400 net.cpp:411] relu1 -> relu1
I1207 02:50:43.296344 2039878400 net.cpp:150] Setting up relu1
I1207 02:50:43.296349 2039878400 net.cpp:157] Top shape: 120 40 (4800)
I1207 02:50:43.296352 2039878400 net.cpp:165] Memory required for data: 268822560
I1207 02:50:43.296356 2039878400 layer_factory.hpp:76] Creating layer fc2
I1207 02:50:43.296370 2039878400 net.cpp:106] Creating Layer fc2
I1207 02:50:43.296373 2039878400 net.cpp:454] fc2 <- relu1
I1207 02:50:43.296378 2039878400 net.cpp:411] fc2 -> fc2
I1207 02:50:43.296393 2039878400 net.cpp:150] Setting up fc2
I1207 02:50:43.296399 2039878400 net.cpp:157] Top shape: 120 4 (480)
I1207 02:50:43.296403 2039878400 net.cpp:165] Memory required for data: 268824480
I1207 02:50:43.296408 2039878400 layer_factory.hpp:76] Creating layer out
I1207 02:50:43.296416 2039878400 net.cpp:106] Creating Layer out
I1207 02:50:43.296421 2039878400 net.cpp:454] out <- fc2
I1207 02:50:43.296425 2039878400 net.cpp:411] out -> out
I1207 02:50:43.296432 2039878400 net.cpp:150] Setting up out
I1207 02:50:43.296437 2039878400 net.cpp:157] Top shape: 120 4 (480)
I1207 02:50:43.296452 2039878400 net.cpp:165] Memory required for data: 268826400
I1207 02:50:43.296465 2039878400 layer_factory.hpp:76] Creating layer loss
I1207 02:50:43.296475 2039878400 net.cpp:106] Creating Layer loss
I1207 02:50:43.296479 2039878400 net.cpp:454] loss <- out
I1207 02:50:43.296509 2039878400 net.cpp:454] loss <- labels
I1207 02:50:43.296525 2039878400 net.cpp:411] loss -> loss
I1207 02:50:43.296546 2039878400 net.cpp:150] Setting up loss
I1207 02:50:43.296550 2039878400 net.cpp:157] Top shape: (1)
I1207 02:50:43.296555 2039878400 net.cpp:160]     with loss weight 1
I1207 02:50:43.296561 2039878400 net.cpp:165] Memory required for data: 268826404
I1207 02:50:43.296566 2039878400 net.cpp:226] loss needs backward computation.
I1207 02:50:43.296571 2039878400 net.cpp:226] out needs backward computation.
I1207 02:50:43.296574 2039878400 net.cpp:226] fc2 needs backward computation.
I1207 02:50:43.296578 2039878400 net.cpp:226] relu1 needs backward computation.
I1207 02:50:43.296582 2039878400 net.cpp:226] fc1 needs backward computation.
I1207 02:50:43.296586 2039878400 net.cpp:226] reluConv2 needs backward computation.
I1207 02:50:43.296591 2039878400 net.cpp:226] conv2 needs backward computation.
I1207 02:50:43.296596 2039878400 net.cpp:226] reluConv1 needs backward computation.
I1207 02:50:43.296599 2039878400 net.cpp:226] conv1 needs backward computation.
I1207 02:50:43.296604 2039878400 net.cpp:228] data does not need backward computation.
I1207 02:50:43.296608 2039878400 net.cpp:270] This network produces output loss
I1207 02:50:43.296623 2039878400 net.cpp:283] Network initialization done.
I1207 02:50:43.296674 2039878400 solver.cpp:59] Solver scaffolding done.
I1207 02:50:43.296703 2039878400 caffe.cpp:212] Starting Optimization
I1207 02:50:43.296711 2039878400 solver.cpp:287] Solving net
I1207 02:50:43.296718 2039878400 solver.cpp:288] Learning Rate Policy: step
I1207 02:50:43.299866 2039878400 solver.cpp:340] Iteration 0, Testing net (#0)
I1207 02:50:45.311851 2039878400 solver.cpp:408]     Test net output #0: loss = 0.314075 (* 1 = 0.314075 loss)
I1207 02:51:08.589668 2039878400 solver.cpp:236] Iteration 0, loss = 0.3005
I1207 02:51:08.589702 2039878400 solver.cpp:252]     Train net output #0: loss = 0.3005 (* 1 = 0.3005 loss)
I1207 02:51:08.589723 2039878400 sgd_solver.cpp:106] Iteration 0, lr = 0.01
I1207 02:51:08.595995 2039878400 solver.cpp:340] Iteration 1, Testing net (#0)
I1207 02:51:10.544291 2039878400 solver.cpp:408]     Test net output #0: loss = 0.246627 (* 1 = 0.246627 loss)
I1207 02:51:32.529168 2039878400 solver.cpp:236] Iteration 1, loss = 0.235386
I1207 02:51:32.529209 2039878400 solver.cpp:252]     Train net output #0: loss = 0.235386 (* 1 = 0.235386 loss)
I1207 02:51:32.529217 2039878400 sgd_solver.cpp:106] Iteration 1, lr = 0.01
I1207 02:51:32.532425 2039878400 solver.cpp:340] Iteration 2, Testing net (#0)
I1207 02:51:34.433014 2039878400 solver.cpp:408]     Test net output #0: loss = 0.206411 (* 1 = 0.206411 loss)
I1207 02:51:56.235658 2039878400 solver.cpp:236] Iteration 2, loss = 0.221899
I1207 02:51:56.235693 2039878400 solver.cpp:252]     Train net output #0: loss = 0.221899 (* 1 = 0.221899 loss)
I1207 02:51:56.235700 2039878400 sgd_solver.cpp:106] Iteration 2, lr = 0.01
I1207 02:51:56.238975 2039878400 solver.cpp:340] Iteration 3, Testing net (#0)
I1207 02:51:58.110496 2039878400 solver.cpp:408]     Test net output #0: loss = 0.215483 (* 1 = 0.215483 loss)
I1207 02:52:19.838069 2039878400 solver.cpp:236] Iteration 3, loss = 0.203657
I1207 02:52:19.838115 2039878400 solver.cpp:252]     Train net output #0: loss = 0.203657 (* 1 = 0.203657 loss)
I1207 02:52:19.838122 2039878400 sgd_solver.cpp:106] Iteration 3, lr = 0.01
I1207 02:52:19.841373 2039878400 solver.cpp:340] Iteration 4, Testing net (#0)
I1207 02:52:21.745970 2039878400 solver.cpp:408]     Test net output #0: loss = 0.183492 (* 1 = 0.183492 loss)
I1207 02:52:43.531904 2039878400 solver.cpp:236] Iteration 4, loss = 0.199169
I1207 02:52:43.531942 2039878400 solver.cpp:252]     Train net output #0: loss = 0.199169 (* 1 = 0.199169 loss)
I1207 02:52:43.531950 2039878400 sgd_solver.cpp:106] Iteration 4, lr = 0.01
I1207 02:52:43.535193 2039878400 solver.cpp:461] Snapshotting to binary proto file weights_iter_5.caffemodel
I1207 02:52:43.624236 2039878400 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_5.solverstate
I1207 02:52:43.695893 2039878400 solver.cpp:340] Iteration 5, Testing net (#0)
I1207 02:52:45.611702 2039878400 solver.cpp:408]     Test net output #0: loss = 0.198088 (* 1 = 0.198088 loss)
I1207 02:53:07.539559 2039878400 solver.cpp:236] Iteration 5, loss = 0.188695
I1207 02:53:07.539623 2039878400 solver.cpp:252]     Train net output #0: loss = 0.188695 (* 1 = 0.188695 loss)
I1207 02:53:07.539631 2039878400 sgd_solver.cpp:106] Iteration 5, lr = 0.01
I1207 02:53:07.542841 2039878400 solver.cpp:340] Iteration 6, Testing net (#0)
I1207 02:53:09.441108 2039878400 solver.cpp:408]     Test net output #0: loss = 0.18429 (* 1 = 0.18429 loss)
I1207 02:53:31.265535 2039878400 solver.cpp:236] Iteration 6, loss = 0.18609
I1207 02:53:31.265566 2039878400 solver.cpp:252]     Train net output #0: loss = 0.18609 (* 1 = 0.18609 loss)
I1207 02:53:31.265574 2039878400 sgd_solver.cpp:106] Iteration 6, lr = 0.01
I1207 02:53:31.268805 2039878400 solver.cpp:340] Iteration 7, Testing net (#0)
I1207 02:53:33.151137 2039878400 solver.cpp:408]     Test net output #0: loss = 0.186469 (* 1 = 0.186469 loss)
I1207 02:53:55.130573 2039878400 solver.cpp:236] Iteration 7, loss = 0.179856
I1207 02:53:55.130617 2039878400 solver.cpp:252]     Train net output #0: loss = 0.179856 (* 1 = 0.179856 loss)
I1207 02:53:55.130625 2039878400 sgd_solver.cpp:106] Iteration 7, lr = 0.01
I1207 02:53:55.134011 2039878400 solver.cpp:340] Iteration 8, Testing net (#0)
I1207 02:53:57.020440 2039878400 solver.cpp:408]     Test net output #0: loss = 0.21024 (* 1 = 0.21024 loss)
I1207 02:54:18.608569 2039878400 solver.cpp:236] Iteration 8, loss = 0.197541
I1207 02:54:18.608603 2039878400 solver.cpp:252]     Train net output #0: loss = 0.197541 (* 1 = 0.197541 loss)
I1207 02:54:18.608611 2039878400 sgd_solver.cpp:106] Iteration 8, lr = 0.01
I1207 02:54:18.612097 2039878400 solver.cpp:340] Iteration 9, Testing net (#0)
I1207 02:54:20.477265 2039878400 solver.cpp:408]     Test net output #0: loss = 0.196964 (* 1 = 0.196964 loss)
I1207 02:54:42.092573 2039878400 solver.cpp:236] Iteration 9, loss = 0.207809
I1207 02:54:42.092620 2039878400 solver.cpp:252]     Train net output #0: loss = 0.207809 (* 1 = 0.207809 loss)
I1207 02:54:42.092628 2039878400 sgd_solver.cpp:106] Iteration 9, lr = 0.01
I1207 02:54:42.095724 2039878400 solver.cpp:461] Snapshotting to binary proto file weights_iter_10.caffemodel
I1207 02:54:42.172184 2039878400 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_10.solverstate
I1207 02:54:42.252197 2039878400 solver.cpp:340] Iteration 10, Testing net (#0)
I1207 02:54:44.149116 2039878400 solver.cpp:408]     Test net output #0: loss = 0.212374 (* 1 = 0.212374 loss)
I1207 02:55:06.003881 2039878400 solver.cpp:236] Iteration 10, loss = 0.206734
I1207 02:55:06.003916 2039878400 solver.cpp:252]     Train net output #0: loss = 0.206734 (* 1 = 0.206734 loss)
I1207 02:55:06.003923 2039878400 sgd_solver.cpp:106] Iteration 10, lr = 0.01
I1207 02:55:06.007227 2039878400 solver.cpp:340] Iteration 11, Testing net (#0)
I1207 02:55:07.953218 2039878400 solver.cpp:408]     Test net output #0: loss = 0.169914 (* 1 = 0.169914 loss)
I1207 02:55:31.487454 2039878400 solver.cpp:236] Iteration 11, loss = 0.177166
I1207 02:55:31.487498 2039878400 solver.cpp:252]     Train net output #0: loss = 0.177166 (* 1 = 0.177166 loss)
I1207 02:55:31.487510 2039878400 sgd_solver.cpp:106] Iteration 11, lr = 0.01
I1207 02:55:31.491174 2039878400 solver.cpp:340] Iteration 12, Testing net (#0)
I1207 02:55:33.517884 2039878400 solver.cpp:408]     Test net output #0: loss = 0.164057 (* 1 = 0.164057 loss)
I1207 02:55:56.337173 2039878400 solver.cpp:236] Iteration 12, loss = 0.170345
I1207 02:55:56.337208 2039878400 solver.cpp:252]     Train net output #0: loss = 0.170345 (* 1 = 0.170345 loss)
I1207 02:55:56.337215 2039878400 sgd_solver.cpp:106] Iteration 12, lr = 0.01
I1207 02:55:56.340713 2039878400 solver.cpp:340] Iteration 13, Testing net (#0)
I1207 02:55:58.312692 2039878400 solver.cpp:408]     Test net output #0: loss = 0.155231 (* 1 = 0.155231 loss)
I1207 02:56:20.859490 2039878400 solver.cpp:236] Iteration 13, loss = 0.158668
I1207 02:56:20.859552 2039878400 solver.cpp:252]     Train net output #0: loss = 0.158668 (* 1 = 0.158668 loss)
I1207 02:56:20.859560 2039878400 sgd_solver.cpp:106] Iteration 13, lr = 0.01
I1207 02:56:20.862877 2039878400 solver.cpp:340] Iteration 14, Testing net (#0)
I1207 02:56:22.833004 2039878400 solver.cpp:408]     Test net output #0: loss = 0.146767 (* 1 = 0.146767 loss)
I1207 02:56:45.975530 2039878400 solver.cpp:236] Iteration 14, loss = 0.157446
I1207 02:56:45.975565 2039878400 solver.cpp:252]     Train net output #0: loss = 0.157446 (* 1 = 0.157446 loss)
I1207 02:56:45.975572 2039878400 sgd_solver.cpp:106] Iteration 14, lr = 0.01
I1207 02:56:45.978706 2039878400 solver.cpp:461] Snapshotting to binary proto file weights_iter_15.caffemodel
I1207 02:56:46.055608 2039878400 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_15.solverstate
I1207 02:56:46.128219 2039878400 solver.cpp:340] Iteration 15, Testing net (#0)
I1207 02:56:48.107661 2039878400 solver.cpp:408]     Test net output #0: loss = 0.155534 (* 1 = 0.155534 loss)
I1207 02:57:11.344873 2039878400 solver.cpp:236] Iteration 15, loss = 0.151307
I1207 02:57:11.344918 2039878400 solver.cpp:252]     Train net output #0: loss = 0.151307 (* 1 = 0.151307 loss)
I1207 02:57:11.344926 2039878400 sgd_solver.cpp:106] Iteration 15, lr = 0.01
I1207 02:57:11.348227 2039878400 solver.cpp:340] Iteration 16, Testing net (#0)
I1207 02:57:13.374960 2039878400 solver.cpp:408]     Test net output #0: loss = 0.157332 (* 1 = 0.157332 loss)
I1207 02:57:36.231446 2039878400 solver.cpp:236] Iteration 16, loss = 0.158604
I1207 02:57:36.231478 2039878400 solver.cpp:252]     Train net output #0: loss = 0.158604 (* 1 = 0.158604 loss)
I1207 02:57:36.231487 2039878400 sgd_solver.cpp:106] Iteration 16, lr = 0.01
I1207 02:57:36.234900 2039878400 solver.cpp:340] Iteration 17, Testing net (#0)
I1207 02:57:38.220119 2039878400 solver.cpp:408]     Test net output #0: loss = 0.176965 (* 1 = 0.176965 loss)
I1207 02:58:00.924298 2039878400 solver.cpp:236] Iteration 17, loss = 0.178348
I1207 02:58:00.924347 2039878400 solver.cpp:252]     Train net output #0: loss = 0.178348 (* 1 = 0.178348 loss)
I1207 02:58:00.924356 2039878400 sgd_solver.cpp:106] Iteration 17, lr = 0.01
I1207 02:58:00.928127 2039878400 solver.cpp:340] Iteration 18, Testing net (#0)
I1207 02:58:02.899348 2039878400 solver.cpp:408]     Test net output #0: loss = 0.19067 (* 1 = 0.19067 loss)
I1207 02:58:25.299474 2039878400 solver.cpp:236] Iteration 18, loss = 0.209843
I1207 02:58:25.299507 2039878400 solver.cpp:252]     Train net output #0: loss = 0.209843 (* 1 = 0.209843 loss)
I1207 02:58:25.299515 2039878400 sgd_solver.cpp:106] Iteration 18, lr = 0.01
I1207 02:58:25.303220 2039878400 solver.cpp:340] Iteration 19, Testing net (#0)
I1207 02:58:27.249321 2039878400 solver.cpp:408]     Test net output #0: loss = 0.163375 (* 1 = 0.163375 loss)
I1207 02:58:49.755657 2039878400 solver.cpp:236] Iteration 19, loss = 0.166182
I1207 02:58:49.755702 2039878400 solver.cpp:252]     Train net output #0: loss = 0.166182 (* 1 = 0.166182 loss)
I1207 02:58:49.755709 2039878400 sgd_solver.cpp:106] Iteration 19, lr = 0.01
I1207 02:58:49.758761 2039878400 solver.cpp:461] Snapshotting to binary proto file weights_iter_20.caffemodel
I1207 02:58:49.839766 2039878400 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_20.solverstate
I1207 02:58:49.914301 2039878400 solver.cpp:340] Iteration 20, Testing net (#0)
I1207 02:58:51.842200 2039878400 solver.cpp:408]     Test net output #0: loss = 0.145107 (* 1 = 0.145107 loss)
I1207 02:59:14.109525 2039878400 solver.cpp:236] Iteration 20, loss = 0.15383
I1207 02:59:14.109560 2039878400 solver.cpp:252]     Train net output #0: loss = 0.15383 (* 1 = 0.15383 loss)
I1207 02:59:14.109567 2039878400 sgd_solver.cpp:106] Iteration 20, lr = 0.01
I1207 02:59:14.112802 2039878400 solver.cpp:340] Iteration 21, Testing net (#0)
I1207 02:59:15.950057 2039878400 solver.cpp:408]     Test net output #0: loss = 0.146864 (* 1 = 0.146864 loss)
I1207 02:59:37.801543 2039878400 solver.cpp:236] Iteration 21, loss = 0.145292
I1207 02:59:37.801604 2039878400 solver.cpp:252]     Train net output #0: loss = 0.145292 (* 1 = 0.145292 loss)
I1207 02:59:37.801614 2039878400 sgd_solver.cpp:106] Iteration 21, lr = 0.01
I1207 02:59:37.804836 2039878400 solver.cpp:340] Iteration 22, Testing net (#0)
I1207 02:59:39.678340 2039878400 solver.cpp:408]     Test net output #0: loss = 0.140882 (* 1 = 0.140882 loss)
I1207 03:00:01.201148 2039878400 solver.cpp:236] Iteration 22, loss = 0.143391
I1207 03:00:01.201175 2039878400 solver.cpp:252]     Train net output #0: loss = 0.143391 (* 1 = 0.143391 loss)
I1207 03:00:01.201184 2039878400 sgd_solver.cpp:106] Iteration 22, lr = 0.01
I1207 03:00:01.204685 2039878400 solver.cpp:340] Iteration 23, Testing net (#0)
I1207 03:00:03.053124 2039878400 solver.cpp:408]     Test net output #0: loss = 0.147751 (* 1 = 0.147751 loss)
I1207 03:00:24.835840 2039878400 solver.cpp:236] Iteration 23, loss = 0.14583
I1207 03:00:24.835888 2039878400 solver.cpp:252]     Train net output #0: loss = 0.14583 (* 1 = 0.14583 loss)
I1207 03:00:24.835896 2039878400 sgd_solver.cpp:106] Iteration 23, lr = 0.01
I1207 03:00:24.839169 2039878400 solver.cpp:340] Iteration 24, Testing net (#0)
I1207 03:00:26.734522 2039878400 solver.cpp:408]     Test net output #0: loss = 0.185058 (* 1 = 0.185058 loss)
I1207 03:00:48.312866 2039878400 solver.cpp:236] Iteration 24, loss = 0.167315
I1207 03:00:48.312894 2039878400 solver.cpp:252]     Train net output #0: loss = 0.167315 (* 1 = 0.167315 loss)
I1207 03:00:48.312901 2039878400 sgd_solver.cpp:106] Iteration 24, lr = 0.01
I1207 03:00:48.315939 2039878400 solver.cpp:461] Snapshotting to binary proto file weights_iter_25.caffemodel
I1207 03:00:48.400488 2039878400 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_25.solverstate
I1207 03:00:48.471534 2039878400 solver.cpp:340] Iteration 25, Testing net (#0)
I1207 03:00:50.418447 2039878400 solver.cpp:408]     Test net output #0: loss = 0.184247 (* 1 = 0.184247 loss)
I1207 03:01:12.645966 2039878400 solver.cpp:236] Iteration 25, loss = 0.191252
I1207 03:01:12.646006 2039878400 solver.cpp:252]     Train net output #0: loss = 0.191252 (* 1 = 0.191252 loss)
I1207 03:01:12.646013 2039878400 sgd_solver.cpp:106] Iteration 25, lr = 0.01
I1207 03:01:12.649391 2039878400 solver.cpp:340] Iteration 26, Testing net (#0)
I1207 03:01:14.576691 2039878400 solver.cpp:408]     Test net output #0: loss = 0.186454 (* 1 = 0.186454 loss)
I1207 03:01:37.336679 2039878400 solver.cpp:236] Iteration 26, loss = 0.17457
I1207 03:01:37.336709 2039878400 solver.cpp:252]     Train net output #0: loss = 0.17457 (* 1 = 0.17457 loss)
I1207 03:01:37.336715 2039878400 sgd_solver.cpp:106] Iteration 26, lr = 0.01
I1207 03:01:37.340101 2039878400 solver.cpp:340] Iteration 27, Testing net (#0)
I1207 03:01:39.329449 2039878400 solver.cpp:408]     Test net output #0: loss = 0.137509 (* 1 = 0.137509 loss)
I1207 03:02:02.045536 2039878400 solver.cpp:236] Iteration 27, loss = 0.148025
I1207 03:02:02.045656 2039878400 solver.cpp:252]     Train net output #0: loss = 0.148025 (* 1 = 0.148025 loss)
I1207 03:02:02.045665 2039878400 sgd_solver.cpp:106] Iteration 27, lr = 0.01
I1207 03:02:02.049573 2039878400 solver.cpp:340] Iteration 28, Testing net (#0)
I1207 03:02:03.971729 2039878400 solver.cpp:408]     Test net output #0: loss = 0.138196 (* 1 = 0.138196 loss)
I1207 03:02:26.413872 2039878400 solver.cpp:236] Iteration 28, loss = 0.140604
I1207 03:02:26.413902 2039878400 solver.cpp:252]     Train net output #0: loss = 0.140604 (* 1 = 0.140604 loss)
I1207 03:02:26.413909 2039878400 sgd_solver.cpp:106] Iteration 28, lr = 0.01
I1207 03:02:26.417148 2039878400 solver.cpp:340] Iteration 29, Testing net (#0)
I1207 03:02:28.333322 2039878400 solver.cpp:408]     Test net output #0: loss = 0.130465 (* 1 = 0.130465 loss)
I1207 03:02:50.689262 2039878400 solver.cpp:236] Iteration 29, loss = 0.135767
I1207 03:02:50.689328 2039878400 solver.cpp:252]     Train net output #0: loss = 0.135767 (* 1 = 0.135767 loss)
I1207 03:02:50.689338 2039878400 sgd_solver.cpp:106] Iteration 29, lr = 0.01
I1207 03:02:50.692355 2039878400 solver.cpp:461] Snapshotting to binary proto file weights_iter_30.caffemodel
I1207 03:02:50.773306 2039878400 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_30.solverstate
I1207 03:02:50.843300 2039878400 solver.cpp:340] Iteration 30, Testing net (#0)
I1207 03:02:52.765641 2039878400 solver.cpp:408]     Test net output #0: loss = 0.127559 (* 1 = 0.127559 loss)
I1207 03:03:14.653883 2039878400 solver.cpp:236] Iteration 30, loss = 0.132596
I1207 03:03:14.653918 2039878400 solver.cpp:252]     Train net output #0: loss = 0.132596 (* 1 = 0.132596 loss)
I1207 03:03:14.653925 2039878400 sgd_solver.cpp:106] Iteration 30, lr = 0.01
I1207 03:03:14.657207 2039878400 solver.cpp:340] Iteration 31, Testing net (#0)
I1207 03:03:16.539932 2039878400 solver.cpp:408]     Test net output #0: loss = 0.133754 (* 1 = 0.133754 loss)
I1207 03:03:38.257319 2039878400 solver.cpp:236] Iteration 31, loss = 0.137723
I1207 03:03:38.257365 2039878400 solver.cpp:252]     Train net output #0: loss = 0.137723 (* 1 = 0.137723 loss)
I1207 03:03:38.257374 2039878400 sgd_solver.cpp:106] Iteration 31, lr = 0.01
I1207 03:03:38.260711 2039878400 solver.cpp:340] Iteration 32, Testing net (#0)
I1207 03:03:40.243110 2039878400 solver.cpp:408]     Test net output #0: loss = 0.140883 (* 1 = 0.140883 loss)
I1207 03:04:01.883893 2039878400 solver.cpp:236] Iteration 32, loss = 0.145046
I1207 03:04:01.883924 2039878400 solver.cpp:252]     Train net output #0: loss = 0.145046 (* 1 = 0.145046 loss)
I1207 03:04:01.883930 2039878400 sgd_solver.cpp:106] Iteration 32, lr = 0.01
I1207 03:04:01.887183 2039878400 solver.cpp:340] Iteration 33, Testing net (#0)
I1207 03:04:03.817332 2039878400 solver.cpp:408]     Test net output #0: loss = 0.157323 (* 1 = 0.157323 loss)
I1207 03:04:26.905498 2039878400 solver.cpp:236] Iteration 33, loss = 0.170567
I1207 03:04:26.905545 2039878400 solver.cpp:252]     Train net output #0: loss = 0.170567 (* 1 = 0.170567 loss)
I1207 03:04:26.905553 2039878400 sgd_solver.cpp:106] Iteration 33, lr = 0.01
I1207 03:04:26.908815 2039878400 solver.cpp:340] Iteration 34, Testing net (#0)
I1207 03:04:28.751092 2039878400 solver.cpp:408]     Test net output #0: loss = 0.178195 (* 1 = 0.178195 loss)
I1207 03:04:49.883005 2039878400 solver.cpp:236] Iteration 34, loss = 0.185603
I1207 03:04:49.883041 2039878400 solver.cpp:252]     Train net output #0: loss = 0.185603 (* 1 = 0.185603 loss)
I1207 03:04:49.883049 2039878400 sgd_solver.cpp:106] Iteration 34, lr = 0.01
I1207 03:04:49.886021 2039878400 solver.cpp:461] Snapshotting to binary proto file weights_iter_35.caffemodel
I1207 03:04:49.969175 2039878400 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_35.solverstate
I1207 03:04:50.038419 2039878400 solver.cpp:340] Iteration 35, Testing net (#0)
I1207 03:04:51.878990 2039878400 solver.cpp:408]     Test net output #0: loss = 0.132376 (* 1 = 0.132376 loss)
I1207 03:05:13.325809 2039878400 solver.cpp:236] Iteration 35, loss = 0.138162
I1207 03:05:13.325850 2039878400 solver.cpp:252]     Train net output #0: loss = 0.138162 (* 1 = 0.138162 loss)
I1207 03:05:13.325858 2039878400 sgd_solver.cpp:106] Iteration 35, lr = 0.01
I1207 03:05:13.329147 2039878400 solver.cpp:340] Iteration 36, Testing net (#0)
I1207 03:05:15.173843 2039878400 solver.cpp:408]     Test net output #0: loss = 0.128984 (* 1 = 0.128984 loss)
I1207 03:05:36.968304 2039878400 solver.cpp:236] Iteration 36, loss = 0.129679
I1207 03:05:36.968333 2039878400 solver.cpp:252]     Train net output #0: loss = 0.129679 (* 1 = 0.129679 loss)
I1207 03:05:36.968340 2039878400 sgd_solver.cpp:106] Iteration 36, lr = 0.01
I1207 03:05:36.971557 2039878400 solver.cpp:340] Iteration 37, Testing net (#0)
I1207 03:05:38.880964 2039878400 solver.cpp:408]     Test net output #0: loss = 0.118361 (* 1 = 0.118361 loss)
I1207 03:06:00.532510 2039878400 solver.cpp:236] Iteration 37, loss = 0.12609
I1207 03:06:00.532569 2039878400 solver.cpp:252]     Train net output #0: loss = 0.12609 (* 1 = 0.12609 loss)
I1207 03:06:00.532578 2039878400 sgd_solver.cpp:106] Iteration 37, lr = 0.01
I1207 03:06:00.535770 2039878400 solver.cpp:340] Iteration 38, Testing net (#0)
I1207 03:06:02.407699 2039878400 solver.cpp:408]     Test net output #0: loss = 0.135422 (* 1 = 0.135422 loss)
I1207 03:06:23.756012 2039878400 solver.cpp:236] Iteration 38, loss = 0.122976
I1207 03:06:23.756047 2039878400 solver.cpp:252]     Train net output #0: loss = 0.122976 (* 1 = 0.122976 loss)
I1207 03:06:23.756053 2039878400 sgd_solver.cpp:106] Iteration 38, lr = 0.01
I1207 03:06:23.759271 2039878400 solver.cpp:340] Iteration 39, Testing net (#0)
I1207 03:06:25.669080 2039878400 solver.cpp:408]     Test net output #0: loss = 0.123368 (* 1 = 0.123368 loss)
I1207 03:06:47.343611 2039878400 solver.cpp:236] Iteration 39, loss = 0.125135
I1207 03:06:47.343653 2039878400 solver.cpp:252]     Train net output #0: loss = 0.125135 (* 1 = 0.125135 loss)
I1207 03:06:47.343662 2039878400 sgd_solver.cpp:106] Iteration 39, lr = 0.01
I1207 03:06:47.346722 2039878400 solver.cpp:461] Snapshotting to binary proto file weights_iter_40.caffemodel
I1207 03:06:47.426798 2039878400 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_40.solverstate
I1207 03:06:47.498198 2039878400 solver.cpp:340] Iteration 40, Testing net (#0)
I1207 03:06:49.375406 2039878400 solver.cpp:408]     Test net output #0: loss = 0.143479 (* 1 = 0.143479 loss)
I1207 03:07:11.396911 2039878400 solver.cpp:236] Iteration 40, loss = 0.130146
I1207 03:07:11.396946 2039878400 solver.cpp:252]     Train net output #0: loss = 0.130146 (* 1 = 0.130146 loss)
I1207 03:07:11.396953 2039878400 sgd_solver.cpp:106] Iteration 40, lr = 0.01
I1207 03:07:11.400320 2039878400 solver.cpp:340] Iteration 41, Testing net (#0)
I1207 03:07:13.283697 2039878400 solver.cpp:408]     Test net output #0: loss = 0.126824 (* 1 = 0.126824 loss)
I1207 03:07:35.046455 2039878400 solver.cpp:236] Iteration 41, loss = 0.140174
I1207 03:07:35.046504 2039878400 solver.cpp:252]     Train net output #0: loss = 0.140174 (* 1 = 0.140174 loss)
I1207 03:07:35.046511 2039878400 sgd_solver.cpp:106] Iteration 41, lr = 0.01
I1207 03:07:35.049731 2039878400 solver.cpp:340] Iteration 42, Testing net (#0)
I1207 03:07:36.892277 2039878400 solver.cpp:408]     Test net output #0: loss = 0.169771 (* 1 = 0.169771 loss)
I1207 03:07:58.031736 2039878400 solver.cpp:236] Iteration 42, loss = 0.160936
I1207 03:07:58.031765 2039878400 solver.cpp:252]     Train net output #0: loss = 0.160936 (* 1 = 0.160936 loss)
I1207 03:07:58.031774 2039878400 sgd_solver.cpp:106] Iteration 42, lr = 0.01
I1207 03:07:58.035007 2039878400 solver.cpp:340] Iteration 43, Testing net (#0)
I1207 03:07:59.871436 2039878400 solver.cpp:408]     Test net output #0: loss = 0.125567 (* 1 = 0.125567 loss)
I1207 03:08:21.018180 2039878400 solver.cpp:236] Iteration 43, loss = 0.137873
I1207 03:08:21.018229 2039878400 solver.cpp:252]     Train net output #0: loss = 0.137873 (* 1 = 0.137873 loss)
I1207 03:08:21.018236 2039878400 sgd_solver.cpp:106] Iteration 43, lr = 0.01
I1207 03:08:21.021441 2039878400 solver.cpp:340] Iteration 44, Testing net (#0)
I1207 03:08:22.857462 2039878400 solver.cpp:408]     Test net output #0: loss = 0.126558 (* 1 = 0.126558 loss)
