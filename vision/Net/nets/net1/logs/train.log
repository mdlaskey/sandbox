I1204 17:10:08.380565 1969066752 caffe.cpp:177] Use CPU.
I1204 17:10:08.992938 1969066752 solver.cpp:47] Initializing solver from parameters: 
test_iter: 1
test_interval: 1
base_lr: 0.001
display: 1
max_iter: 300
lr_policy: "step"
gamma: 1e-05
momentum: 0.9
weight_decay: 0.0005
stepsize: 20
snapshot: 20
snapshot_prefix: "weights"
solver_mode: CPU
net: "/Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net1/trainer1.prototxt"
I1204 17:10:08.993235 1969066752 solver.cpp:90] Creating training net from net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net1/trainer1.prototxt
I1204 17:10:08.993444 1969066752 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1204 17:10:08.993471 1969066752 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt"
    batch_size: 450
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "conv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "fc1"
  top: "relu1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "relu1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1204 17:10:08.993587 1969066752 layer_factory.hpp:76] Creating layer data
I1204 17:10:08.993598 1969066752 net.cpp:106] Creating Layer data
I1204 17:10:08.993605 1969066752 net.cpp:411] data -> data
I1204 17:10:08.993623 1969066752 net.cpp:411] data -> labels
I1204 17:10:08.993638 1969066752 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt
I1204 17:10:08.993675 1969066752 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1204 17:10:08.994597 1969066752 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1204 17:10:09.175994 1969066752 net.cpp:150] Setting up data
I1204 17:10:09.176028 1969066752 net.cpp:157] Top shape: 450 3 125 125 (21093750)
I1204 17:10:09.176038 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 17:10:09.176043 1969066752 net.cpp:165] Memory required for data: 84382200
I1204 17:10:09.176049 1969066752 layer_factory.hpp:76] Creating layer conv1
I1204 17:10:09.176064 1969066752 net.cpp:106] Creating Layer conv1
I1204 17:10:09.176079 1969066752 net.cpp:454] conv1 <- data
I1204 17:10:09.176110 1969066752 net.cpp:411] conv1 -> conv1
I1204 17:10:09.180366 1969066752 net.cpp:150] Setting up conv1
I1204 17:10:09.180374 1969066752 net.cpp:157] Top shape: 450 16 115 115 (95220000)
I1204 17:10:09.180392 1969066752 net.cpp:165] Memory required for data: 465262200
I1204 17:10:09.180399 1969066752 layer_factory.hpp:76] Creating layer reluConv
I1204 17:10:09.180480 1969066752 net.cpp:106] Creating Layer reluConv
I1204 17:10:09.180490 1969066752 net.cpp:454] reluConv <- conv1
I1204 17:10:09.180498 1969066752 net.cpp:397] reluConv -> conv1 (in-place)
I1204 17:10:09.180506 1969066752 net.cpp:150] Setting up reluConv
I1204 17:10:09.180511 1969066752 net.cpp:157] Top shape: 450 16 115 115 (95220000)
I1204 17:10:09.180517 1969066752 net.cpp:165] Memory required for data: 846142200
I1204 17:10:09.180522 1969066752 layer_factory.hpp:76] Creating layer conv2
I1204 17:10:09.180531 1969066752 net.cpp:106] Creating Layer conv2
I1204 17:10:09.180536 1969066752 net.cpp:454] conv2 <- conv1
I1204 17:10:09.180541 1969066752 net.cpp:411] conv2 -> conv2
I1204 17:10:09.180872 1969066752 net.cpp:150] Setting up conv2
I1204 17:10:09.180877 1969066752 net.cpp:157] Top shape: 450 16 53 53 (20224800)
I1204 17:10:09.180893 1969066752 net.cpp:165] Memory required for data: 927041400
I1204 17:10:09.180902 1969066752 layer_factory.hpp:76] Creating layer fc1
I1204 17:10:09.180908 1969066752 net.cpp:106] Creating Layer fc1
I1204 17:10:09.180923 1969066752 net.cpp:454] fc1 <- conv2
I1204 17:10:09.180932 1969066752 net.cpp:411] fc1 -> fc1
I1204 17:10:09.194514 1969066752 net.cpp:150] Setting up fc1
I1204 17:10:09.194533 1969066752 net.cpp:157] Top shape: 450 40 (18000)
I1204 17:10:09.194550 1969066752 net.cpp:165] Memory required for data: 927113400
I1204 17:10:09.194627 1969066752 layer_factory.hpp:76] Creating layer relu1
I1204 17:10:09.194640 1969066752 net.cpp:106] Creating Layer relu1
I1204 17:10:09.194646 1969066752 net.cpp:454] relu1 <- fc1
I1204 17:10:09.194653 1969066752 net.cpp:411] relu1 -> relu1
I1204 17:10:09.194664 1969066752 net.cpp:150] Setting up relu1
I1204 17:10:09.194667 1969066752 net.cpp:157] Top shape: 450 40 (18000)
I1204 17:10:09.194672 1969066752 net.cpp:165] Memory required for data: 927185400
I1204 17:10:09.194677 1969066752 layer_factory.hpp:76] Creating layer fc2
I1204 17:10:09.194684 1969066752 net.cpp:106] Creating Layer fc2
I1204 17:10:09.194689 1969066752 net.cpp:454] fc2 <- relu1
I1204 17:10:09.194703 1969066752 net.cpp:411] fc2 -> fc2
I1204 17:10:09.194723 1969066752 net.cpp:150] Setting up fc2
I1204 17:10:09.194727 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 17:10:09.194732 1969066752 net.cpp:165] Memory required for data: 927192600
I1204 17:10:09.194738 1969066752 layer_factory.hpp:76] Creating layer out
I1204 17:10:09.194744 1969066752 net.cpp:106] Creating Layer out
I1204 17:10:09.194748 1969066752 net.cpp:454] out <- fc2
I1204 17:10:09.194759 1969066752 net.cpp:411] out -> out
I1204 17:10:09.194766 1969066752 net.cpp:150] Setting up out
I1204 17:10:09.194771 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 17:10:09.194774 1969066752 net.cpp:165] Memory required for data: 927199800
I1204 17:10:09.194779 1969066752 layer_factory.hpp:76] Creating layer loss
I1204 17:10:09.194788 1969066752 net.cpp:106] Creating Layer loss
I1204 17:10:09.194792 1969066752 net.cpp:454] loss <- out
I1204 17:10:09.194797 1969066752 net.cpp:454] loss <- labels
I1204 17:10:09.194802 1969066752 net.cpp:411] loss -> loss
I1204 17:10:09.194814 1969066752 net.cpp:150] Setting up loss
I1204 17:10:09.194819 1969066752 net.cpp:157] Top shape: (1)
I1204 17:10:09.194823 1969066752 net.cpp:160]     with loss weight 1
I1204 17:10:09.194836 1969066752 net.cpp:165] Memory required for data: 927199804
I1204 17:10:09.194840 1969066752 net.cpp:226] loss needs backward computation.
I1204 17:10:09.194854 1969066752 net.cpp:226] out needs backward computation.
I1204 17:10:09.194859 1969066752 net.cpp:226] fc2 needs backward computation.
I1204 17:10:09.194872 1969066752 net.cpp:226] relu1 needs backward computation.
I1204 17:10:09.194876 1969066752 net.cpp:226] fc1 needs backward computation.
I1204 17:10:09.194880 1969066752 net.cpp:226] conv2 needs backward computation.
I1204 17:10:09.194885 1969066752 net.cpp:226] reluConv needs backward computation.
I1204 17:10:09.194888 1969066752 net.cpp:226] conv1 needs backward computation.
I1204 17:10:09.194892 1969066752 net.cpp:228] data does not need backward computation.
I1204 17:10:09.194922 1969066752 net.cpp:270] This network produces output loss
I1204 17:10:09.194932 1969066752 net.cpp:283] Network initialization done.
I1204 17:10:09.195168 1969066752 solver.cpp:180] Creating test net (#0) specified by net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net1/trainer1.prototxt
I1204 17:10:09.195202 1969066752 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1204 17:10:09.195225 1969066752 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt"
    batch_size: 120
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "conv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "fc1"
  top: "relu1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "relu1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1204 17:10:09.195353 1969066752 layer_factory.hpp:76] Creating layer data
I1204 17:10:09.195363 1969066752 net.cpp:106] Creating Layer data
I1204 17:10:09.195372 1969066752 net.cpp:411] data -> data
I1204 17:10:09.195384 1969066752 net.cpp:411] data -> labels
I1204 17:10:09.195390 1969066752 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt
I1204 17:10:09.195430 1969066752 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1204 17:10:09.245944 1969066752 net.cpp:150] Setting up data
I1204 17:10:09.245967 1969066752 net.cpp:157] Top shape: 120 3 125 125 (5625000)
I1204 17:10:09.245975 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 17:10:09.245980 1969066752 net.cpp:165] Memory required for data: 22501920
I1204 17:10:09.245985 1969066752 layer_factory.hpp:76] Creating layer conv1
I1204 17:10:09.245996 1969066752 net.cpp:106] Creating Layer conv1
I1204 17:10:09.246001 1969066752 net.cpp:454] conv1 <- data
I1204 17:10:09.246014 1969066752 net.cpp:411] conv1 -> conv1
I1204 17:10:09.246106 1969066752 net.cpp:150] Setting up conv1
I1204 17:10:09.246111 1969066752 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1204 17:10:09.246116 1969066752 net.cpp:165] Memory required for data: 124069920
I1204 17:10:09.246124 1969066752 layer_factory.hpp:76] Creating layer reluConv
I1204 17:10:09.246130 1969066752 net.cpp:106] Creating Layer reluConv
I1204 17:10:09.246134 1969066752 net.cpp:454] reluConv <- conv1
I1204 17:10:09.246140 1969066752 net.cpp:397] reluConv -> conv1 (in-place)
I1204 17:10:09.246165 1969066752 net.cpp:150] Setting up reluConv
I1204 17:10:09.246170 1969066752 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1204 17:10:09.246176 1969066752 net.cpp:165] Memory required for data: 225637920
I1204 17:10:09.246179 1969066752 layer_factory.hpp:76] Creating layer conv2
I1204 17:10:09.246186 1969066752 net.cpp:106] Creating Layer conv2
I1204 17:10:09.246189 1969066752 net.cpp:454] conv2 <- conv1
I1204 17:10:09.246194 1969066752 net.cpp:411] conv2 -> conv2
I1204 17:10:09.246474 1969066752 net.cpp:150] Setting up conv2
I1204 17:10:09.246479 1969066752 net.cpp:157] Top shape: 120 16 53 53 (5393280)
I1204 17:10:09.246491 1969066752 net.cpp:165] Memory required for data: 247211040
I1204 17:10:09.246510 1969066752 layer_factory.hpp:76] Creating layer fc1
I1204 17:10:09.246517 1969066752 net.cpp:106] Creating Layer fc1
I1204 17:10:09.246520 1969066752 net.cpp:454] fc1 <- conv2
I1204 17:10:09.246537 1969066752 net.cpp:411] fc1 -> fc1
I1204 17:10:09.260196 1969066752 net.cpp:150] Setting up fc1
I1204 17:10:09.260208 1969066752 net.cpp:157] Top shape: 120 40 (4800)
I1204 17:10:09.260213 1969066752 net.cpp:165] Memory required for data: 247230240
I1204 17:10:09.260224 1969066752 layer_factory.hpp:76] Creating layer relu1
I1204 17:10:09.260231 1969066752 net.cpp:106] Creating Layer relu1
I1204 17:10:09.260234 1969066752 net.cpp:454] relu1 <- fc1
I1204 17:10:09.260238 1969066752 net.cpp:411] relu1 -> relu1
I1204 17:10:09.260246 1969066752 net.cpp:150] Setting up relu1
I1204 17:10:09.260249 1969066752 net.cpp:157] Top shape: 120 40 (4800)
I1204 17:10:09.260253 1969066752 net.cpp:165] Memory required for data: 247249440
I1204 17:10:09.260257 1969066752 layer_factory.hpp:76] Creating layer fc2
I1204 17:10:09.260262 1969066752 net.cpp:106] Creating Layer fc2
I1204 17:10:09.260267 1969066752 net.cpp:454] fc2 <- relu1
I1204 17:10:09.260273 1969066752 net.cpp:411] fc2 -> fc2
I1204 17:10:09.260287 1969066752 net.cpp:150] Setting up fc2
I1204 17:10:09.260290 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 17:10:09.260294 1969066752 net.cpp:165] Memory required for data: 247251360
I1204 17:10:09.260299 1969066752 layer_factory.hpp:76] Creating layer out
I1204 17:10:09.260308 1969066752 net.cpp:106] Creating Layer out
I1204 17:10:09.260313 1969066752 net.cpp:454] out <- fc2
I1204 17:10:09.260318 1969066752 net.cpp:411] out -> out
I1204 17:10:09.260324 1969066752 net.cpp:150] Setting up out
I1204 17:10:09.260327 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 17:10:09.260331 1969066752 net.cpp:165] Memory required for data: 247253280
I1204 17:10:09.260335 1969066752 layer_factory.hpp:76] Creating layer loss
I1204 17:10:09.260344 1969066752 net.cpp:106] Creating Layer loss
I1204 17:10:09.260347 1969066752 net.cpp:454] loss <- out
I1204 17:10:09.260352 1969066752 net.cpp:454] loss <- labels
I1204 17:10:09.260357 1969066752 net.cpp:411] loss -> loss
I1204 17:10:09.260365 1969066752 net.cpp:150] Setting up loss
I1204 17:10:09.260370 1969066752 net.cpp:157] Top shape: (1)
I1204 17:10:09.260373 1969066752 net.cpp:160]     with loss weight 1
I1204 17:10:09.260380 1969066752 net.cpp:165] Memory required for data: 247253284
I1204 17:10:09.260385 1969066752 net.cpp:226] loss needs backward computation.
I1204 17:10:09.260387 1969066752 net.cpp:226] out needs backward computation.
I1204 17:10:09.260391 1969066752 net.cpp:226] fc2 needs backward computation.
I1204 17:10:09.260395 1969066752 net.cpp:226] relu1 needs backward computation.
I1204 17:10:09.260398 1969066752 net.cpp:226] fc1 needs backward computation.
I1204 17:10:09.260401 1969066752 net.cpp:226] conv2 needs backward computation.
I1204 17:10:09.260406 1969066752 net.cpp:226] reluConv needs backward computation.
I1204 17:10:09.260408 1969066752 net.cpp:226] conv1 needs backward computation.
I1204 17:10:09.260412 1969066752 net.cpp:228] data does not need backward computation.
I1204 17:10:09.260416 1969066752 net.cpp:270] This network produces output loss
I1204 17:10:09.260422 1969066752 net.cpp:283] Network initialization done.
I1204 17:10:09.260481 1969066752 solver.cpp:59] Solver scaffolding done.
I1204 17:10:09.260510 1969066752 caffe.cpp:212] Starting Optimization
I1204 17:10:09.260515 1969066752 solver.cpp:287] Solving net
I1204 17:10:09.260519 1969066752 solver.cpp:288] Learning Rate Policy: step
I1204 17:10:09.263425 1969066752 solver.cpp:340] Iteration 0, Testing net (#0)
