I1204 04:10:04.317198 1969066752 caffe.cpp:177] Use CPU.
I1204 04:10:04.597034 1969066752 solver.cpp:47] Initializing solver from parameters: 
test_iter: 1
test_interval: 1
base_lr: 0.001
display: 1
max_iter: 300
lr_policy: "step"
gamma: 1e-05
momentum: 0.9
weight_decay: 0.0005
stepsize: 10
snapshot: 5
snapshot_prefix: "weights"
solver_mode: CPU
net: "/Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net9/trainer9.prototxt"
I1204 04:10:04.597291 1969066752 solver.cpp:90] Creating training net from net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net9/trainer9.prototxt
I1204 04:10:04.597597 1969066752 net.cpp:322] The NetState phase (0) differed from the phase (1) specified by a rule in layer data
I1204 04:10:04.597620 1969066752 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TRAIN
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TRAIN
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt"
    batch_size: 450
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "conv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1204 04:10:04.597821 1969066752 layer_factory.hpp:76] Creating layer data
I1204 04:10:04.597857 1969066752 net.cpp:106] Creating Layer data
I1204 04:10:04.597877 1969066752 net.cpp:411] data -> data
I1204 04:10:04.597911 1969066752 net.cpp:411] data -> labels
I1204 04:10:04.597937 1969066752 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/train_hdf.txt
I1204 04:10:04.598027 1969066752 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1204 04:10:04.599606 1969066752 hdf5.cpp:32] Datatype class: H5T_FLOAT
I1204 04:10:04.868242 1969066752 net.cpp:150] Setting up data
I1204 04:10:04.868294 1969066752 net.cpp:157] Top shape: 450 3 125 125 (21093750)
I1204 04:10:04.868336 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 04:10:04.868348 1969066752 net.cpp:165] Memory required for data: 84382200
I1204 04:10:04.868383 1969066752 layer_factory.hpp:76] Creating layer conv1
I1204 04:10:04.868409 1969066752 net.cpp:106] Creating Layer conv1
I1204 04:10:04.868423 1969066752 net.cpp:454] conv1 <- data
I1204 04:10:04.868441 1969066752 net.cpp:411] conv1 -> conv1
I1204 04:10:04.875340 1969066752 net.cpp:150] Setting up conv1
I1204 04:10:04.875358 1969066752 net.cpp:157] Top shape: 450 16 115 115 (95220000)
I1204 04:10:04.875390 1969066752 net.cpp:165] Memory required for data: 465262200
I1204 04:10:04.875417 1969066752 layer_factory.hpp:76] Creating layer reluConv1
I1204 04:10:04.875464 1969066752 net.cpp:106] Creating Layer reluConv1
I1204 04:10:04.875488 1969066752 net.cpp:454] reluConv1 <- conv1
I1204 04:10:04.875517 1969066752 net.cpp:397] reluConv1 -> conv1 (in-place)
I1204 04:10:04.875565 1969066752 net.cpp:150] Setting up reluConv1
I1204 04:10:04.875578 1969066752 net.cpp:157] Top shape: 450 16 115 115 (95220000)
I1204 04:10:04.875624 1969066752 net.cpp:165] Memory required for data: 846142200
I1204 04:10:04.875648 1969066752 layer_factory.hpp:76] Creating layer conv2
I1204 04:10:04.875713 1969066752 net.cpp:106] Creating Layer conv2
I1204 04:10:04.875731 1969066752 net.cpp:454] conv2 <- conv1
I1204 04:10:04.875788 1969066752 net.cpp:411] conv2 -> conv2
I1204 04:10:04.876201 1969066752 net.cpp:150] Setting up conv2
I1204 04:10:04.876212 1969066752 net.cpp:157] Top shape: 450 16 53 53 (20224800)
I1204 04:10:04.876219 1969066752 net.cpp:165] Memory required for data: 927041400
I1204 04:10:04.876226 1969066752 layer_factory.hpp:76] Creating layer reluConv2
I1204 04:10:04.876233 1969066752 net.cpp:106] Creating Layer reluConv2
I1204 04:10:04.876272 1969066752 net.cpp:454] reluConv2 <- conv2
I1204 04:10:04.876297 1969066752 net.cpp:397] reluConv2 -> conv2 (in-place)
I1204 04:10:04.876320 1969066752 net.cpp:150] Setting up reluConv2
I1204 04:10:04.876353 1969066752 net.cpp:157] Top shape: 450 16 53 53 (20224800)
I1204 04:10:04.876374 1969066752 net.cpp:165] Memory required for data: 1007940600
I1204 04:10:04.876407 1969066752 layer_factory.hpp:76] Creating layer fc1
I1204 04:10:04.876451 1969066752 net.cpp:106] Creating Layer fc1
I1204 04:10:04.876466 1969066752 net.cpp:454] fc1 <- conv2
I1204 04:10:04.876482 1969066752 net.cpp:411] fc1 -> fc1
I1204 04:10:04.898413 1969066752 net.cpp:150] Setting up fc1
I1204 04:10:04.898432 1969066752 net.cpp:157] Top shape: 450 40 (18000)
I1204 04:10:04.898437 1969066752 net.cpp:165] Memory required for data: 1008012600
I1204 04:10:04.898447 1969066752 layer_factory.hpp:76] Creating layer relu1
I1204 04:10:04.898458 1969066752 net.cpp:106] Creating Layer relu1
I1204 04:10:04.898474 1969066752 net.cpp:454] relu1 <- fc1
I1204 04:10:04.898516 1969066752 net.cpp:397] relu1 -> fc1 (in-place)
I1204 04:10:04.898557 1969066752 net.cpp:150] Setting up relu1
I1204 04:10:04.898576 1969066752 net.cpp:157] Top shape: 450 40 (18000)
I1204 04:10:04.898618 1969066752 net.cpp:165] Memory required for data: 1008084600
I1204 04:10:04.898634 1969066752 layer_factory.hpp:76] Creating layer fc2
I1204 04:10:04.898663 1969066752 net.cpp:106] Creating Layer fc2
I1204 04:10:04.898679 1969066752 net.cpp:454] fc2 <- fc1
I1204 04:10:04.898720 1969066752 net.cpp:411] fc2 -> fc2
I1204 04:10:04.898790 1969066752 net.cpp:150] Setting up fc2
I1204 04:10:04.898805 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 04:10:04.898833 1969066752 net.cpp:165] Memory required for data: 1008091800
I1204 04:10:04.898844 1969066752 layer_factory.hpp:76] Creating layer relu2
I1204 04:10:04.898862 1969066752 net.cpp:106] Creating Layer relu2
I1204 04:10:04.898883 1969066752 net.cpp:454] relu2 <- fc2
I1204 04:10:04.898898 1969066752 net.cpp:397] relu2 -> fc2 (in-place)
I1204 04:10:04.898921 1969066752 net.cpp:150] Setting up relu2
I1204 04:10:04.898941 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 04:10:04.898972 1969066752 net.cpp:165] Memory required for data: 1008099000
I1204 04:10:04.898988 1969066752 layer_factory.hpp:76] Creating layer out
I1204 04:10:04.899000 1969066752 net.cpp:106] Creating Layer out
I1204 04:10:04.899008 1969066752 net.cpp:454] out <- fc2
I1204 04:10:04.899039 1969066752 net.cpp:411] out -> out
I1204 04:10:04.899057 1969066752 net.cpp:150] Setting up out
I1204 04:10:04.899065 1969066752 net.cpp:157] Top shape: 450 4 (1800)
I1204 04:10:04.899072 1969066752 net.cpp:165] Memory required for data: 1008106200
I1204 04:10:04.899080 1969066752 layer_factory.hpp:76] Creating layer loss
I1204 04:10:04.899139 1969066752 net.cpp:106] Creating Layer loss
I1204 04:10:04.899189 1969066752 net.cpp:454] loss <- out
I1204 04:10:04.899215 1969066752 net.cpp:454] loss <- labels
I1204 04:10:04.899246 1969066752 net.cpp:411] loss -> loss
I1204 04:10:04.899313 1969066752 net.cpp:150] Setting up loss
I1204 04:10:04.899329 1969066752 net.cpp:157] Top shape: (1)
I1204 04:10:04.899356 1969066752 net.cpp:160]     with loss weight 1
I1204 04:10:04.899385 1969066752 net.cpp:165] Memory required for data: 1008106204
I1204 04:10:04.899420 1969066752 net.cpp:226] loss needs backward computation.
I1204 04:10:04.899440 1969066752 net.cpp:226] out needs backward computation.
I1204 04:10:04.899462 1969066752 net.cpp:226] relu2 needs backward computation.
I1204 04:10:04.899479 1969066752 net.cpp:226] fc2 needs backward computation.
I1204 04:10:04.899489 1969066752 net.cpp:226] relu1 needs backward computation.
I1204 04:10:04.899495 1969066752 net.cpp:226] fc1 needs backward computation.
I1204 04:10:04.899523 1969066752 net.cpp:226] reluConv2 needs backward computation.
I1204 04:10:04.899544 1969066752 net.cpp:226] conv2 needs backward computation.
I1204 04:10:04.899564 1969066752 net.cpp:226] reluConv1 needs backward computation.
I1204 04:10:04.899600 1969066752 net.cpp:226] conv1 needs backward computation.
I1204 04:10:04.899631 1969066752 net.cpp:228] data does not need backward computation.
I1204 04:10:04.899654 1969066752 net.cpp:270] This network produces output loss
I1204 04:10:04.899678 1969066752 net.cpp:283] Network initialization done.
I1204 04:10:04.899950 1969066752 solver.cpp:180] Creating test net (#0) specified by net file: /Users/JonathanLee/Desktop/sandbox/vision/Net/nets/net9/trainer9.prototxt
I1204 04:10:04.899974 1969066752 net.cpp:322] The NetState phase (1) differed from the phase (0) specified by a rule in layer data
I1204 04:10:04.899996 1969066752 net.cpp:49] Initializing net from parameters: 
name: "net"
state {
  phase: TEST
}
layer {
  name: "data"
  type: "HDF5Data"
  top: "data"
  top: "labels"
  include {
    phase: TEST
  }
  hdf5_data_param {
    source: "/Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt"
    batch_size: 120
  }
}
layer {
  name: "conv1"
  type: "Convolution"
  bottom: "data"
  top: "conv1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 1
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv1"
  type: "ReLU"
  bottom: "conv1"
  top: "conv1"
}
layer {
  name: "conv2"
  type: "Convolution"
  bottom: "conv1"
  top: "conv2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  convolution_param {
    num_output: 16
    kernel_size: 11
    stride: 2
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "reluConv2"
  type: "ReLU"
  bottom: "conv2"
  top: "conv2"
}
layer {
  name: "fc1"
  type: "InnerProduct"
  bottom: "conv2"
  top: "fc1"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 40
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu1"
  type: "ReLU"
  bottom: "fc1"
  top: "fc1"
}
layer {
  name: "fc2"
  type: "InnerProduct"
  bottom: "fc1"
  top: "fc2"
  param {
    lr_mult: 1
    decay_mult: 1
  }
  param {
    lr_mult: 2
    decay_mult: 0
  }
  inner_product_param {
    num_output: 4
    weight_filler {
      type: "xavier"
    }
    bias_filler {
      type: "constant"
      value: 0
    }
  }
}
layer {
  name: "relu2"
  type: "ReLU"
  bottom: "fc2"
  top: "fc2"
}
layer {
  name: "out"
  type: "TanH"
  bottom: "fc2"
  top: "out"
}
layer {
  name: "loss"
  type: "EuclideanLoss"
  bottom: "out"
  bottom: "labels"
  top: "loss"
}
I1204 04:10:04.900125 1969066752 layer_factory.hpp:76] Creating layer data
I1204 04:10:04.900209 1969066752 net.cpp:106] Creating Layer data
I1204 04:10:04.900238 1969066752 net.cpp:411] data -> data
I1204 04:10:04.900264 1969066752 net.cpp:411] data -> labels
I1204 04:10:04.900285 1969066752 hdf5_data_layer.cpp:79] Loading list of HDF5 filenames from: /Users/JonathanLee/Desktop/sandbox/vision/Net/hdf/test_hdf.txt
I1204 04:10:04.900321 1969066752 hdf5_data_layer.cpp:93] Number of HDF5 files: 1
I1204 04:10:04.977319 1969066752 net.cpp:150] Setting up data
I1204 04:10:04.977341 1969066752 net.cpp:157] Top shape: 120 3 125 125 (5625000)
I1204 04:10:04.977352 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 04:10:04.977360 1969066752 net.cpp:165] Memory required for data: 22501920
I1204 04:10:04.977367 1969066752 layer_factory.hpp:76] Creating layer conv1
I1204 04:10:04.977401 1969066752 net.cpp:106] Creating Layer conv1
I1204 04:10:04.977427 1969066752 net.cpp:454] conv1 <- data
I1204 04:10:04.977458 1969066752 net.cpp:411] conv1 -> conv1
I1204 04:10:04.977612 1969066752 net.cpp:150] Setting up conv1
I1204 04:10:04.977620 1969066752 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1204 04:10:04.977627 1969066752 net.cpp:165] Memory required for data: 124069920
I1204 04:10:04.977660 1969066752 layer_factory.hpp:76] Creating layer reluConv1
I1204 04:10:04.977679 1969066752 net.cpp:106] Creating Layer reluConv1
I1204 04:10:04.977696 1969066752 net.cpp:454] reluConv1 <- conv1
I1204 04:10:04.977723 1969066752 net.cpp:397] reluConv1 -> conv1 (in-place)
I1204 04:10:04.977758 1969066752 net.cpp:150] Setting up reluConv1
I1204 04:10:04.977782 1969066752 net.cpp:157] Top shape: 120 16 115 115 (25392000)
I1204 04:10:04.977805 1969066752 net.cpp:165] Memory required for data: 225637920
I1204 04:10:04.977812 1969066752 layer_factory.hpp:76] Creating layer conv2
I1204 04:10:04.977823 1969066752 net.cpp:106] Creating Layer conv2
I1204 04:10:04.977826 1969066752 net.cpp:454] conv2 <- conv1
I1204 04:10:04.977831 1969066752 net.cpp:411] conv2 -> conv2
I1204 04:10:04.978152 1969066752 net.cpp:150] Setting up conv2
I1204 04:10:04.978163 1969066752 net.cpp:157] Top shape: 120 16 53 53 (5393280)
I1204 04:10:04.978168 1969066752 net.cpp:165] Memory required for data: 247211040
I1204 04:10:04.978176 1969066752 layer_factory.hpp:76] Creating layer reluConv2
I1204 04:10:04.978183 1969066752 net.cpp:106] Creating Layer reluConv2
I1204 04:10:04.978199 1969066752 net.cpp:454] reluConv2 <- conv2
I1204 04:10:04.978211 1969066752 net.cpp:397] reluConv2 -> conv2 (in-place)
I1204 04:10:04.978221 1969066752 net.cpp:150] Setting up reluConv2
I1204 04:10:04.978227 1969066752 net.cpp:157] Top shape: 120 16 53 53 (5393280)
I1204 04:10:04.978250 1969066752 net.cpp:165] Memory required for data: 268784160
I1204 04:10:04.978263 1969066752 layer_factory.hpp:76] Creating layer fc1
I1204 04:10:04.978276 1969066752 net.cpp:106] Creating Layer fc1
I1204 04:10:04.978282 1969066752 net.cpp:454] fc1 <- conv2
I1204 04:10:04.978315 1969066752 net.cpp:411] fc1 -> fc1
I1204 04:10:04.998826 1969066752 net.cpp:150] Setting up fc1
I1204 04:10:04.998843 1969066752 net.cpp:157] Top shape: 120 40 (4800)
I1204 04:10:04.998848 1969066752 net.cpp:165] Memory required for data: 268803360
I1204 04:10:04.998858 1969066752 layer_factory.hpp:76] Creating layer relu1
I1204 04:10:04.998865 1969066752 net.cpp:106] Creating Layer relu1
I1204 04:10:04.998880 1969066752 net.cpp:454] relu1 <- fc1
I1204 04:10:04.998939 1969066752 net.cpp:397] relu1 -> fc1 (in-place)
I1204 04:10:04.998966 1969066752 net.cpp:150] Setting up relu1
I1204 04:10:04.998991 1969066752 net.cpp:157] Top shape: 120 40 (4800)
I1204 04:10:04.999022 1969066752 net.cpp:165] Memory required for data: 268822560
I1204 04:10:04.999037 1969066752 layer_factory.hpp:76] Creating layer fc2
I1204 04:10:04.999048 1969066752 net.cpp:106] Creating Layer fc2
I1204 04:10:04.999055 1969066752 net.cpp:454] fc2 <- fc1
I1204 04:10:04.999083 1969066752 net.cpp:411] fc2 -> fc2
I1204 04:10:04.999122 1969066752 net.cpp:150] Setting up fc2
I1204 04:10:04.999138 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 04:10:04.999191 1969066752 net.cpp:165] Memory required for data: 268824480
I1204 04:10:04.999222 1969066752 layer_factory.hpp:76] Creating layer relu2
I1204 04:10:04.999269 1969066752 net.cpp:106] Creating Layer relu2
I1204 04:10:04.999295 1969066752 net.cpp:454] relu2 <- fc2
I1204 04:10:04.999317 1969066752 net.cpp:397] relu2 -> fc2 (in-place)
I1204 04:10:04.999359 1969066752 net.cpp:150] Setting up relu2
I1204 04:10:04.999374 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 04:10:04.999380 1969066752 net.cpp:165] Memory required for data: 268826400
I1204 04:10:04.999384 1969066752 layer_factory.hpp:76] Creating layer out
I1204 04:10:04.999390 1969066752 net.cpp:106] Creating Layer out
I1204 04:10:04.999394 1969066752 net.cpp:454] out <- fc2
I1204 04:10:04.999411 1969066752 net.cpp:411] out -> out
I1204 04:10:04.999459 1969066752 net.cpp:150] Setting up out
I1204 04:10:04.999501 1969066752 net.cpp:157] Top shape: 120 4 (480)
I1204 04:10:04.999516 1969066752 net.cpp:165] Memory required for data: 268828320
I1204 04:10:04.999555 1969066752 layer_factory.hpp:76] Creating layer loss
I1204 04:10:04.999578 1969066752 net.cpp:106] Creating Layer loss
I1204 04:10:04.999596 1969066752 net.cpp:454] loss <- out
I1204 04:10:04.999639 1969066752 net.cpp:454] loss <- labels
I1204 04:10:04.999686 1969066752 net.cpp:411] loss -> loss
I1204 04:10:04.999722 1969066752 net.cpp:150] Setting up loss
I1204 04:10:04.999738 1969066752 net.cpp:157] Top shape: (1)
I1204 04:10:04.999747 1969066752 net.cpp:160]     with loss weight 1
I1204 04:10:04.999768 1969066752 net.cpp:165] Memory required for data: 268828324
I1204 04:10:04.999775 1969066752 net.cpp:226] loss needs backward computation.
I1204 04:10:04.999779 1969066752 net.cpp:226] out needs backward computation.
I1204 04:10:04.999783 1969066752 net.cpp:226] relu2 needs backward computation.
I1204 04:10:04.999799 1969066752 net.cpp:226] fc2 needs backward computation.
I1204 04:10:04.999804 1969066752 net.cpp:226] relu1 needs backward computation.
I1204 04:10:04.999806 1969066752 net.cpp:226] fc1 needs backward computation.
I1204 04:10:04.999810 1969066752 net.cpp:226] reluConv2 needs backward computation.
I1204 04:10:04.999814 1969066752 net.cpp:226] conv2 needs backward computation.
I1204 04:10:04.999817 1969066752 net.cpp:226] reluConv1 needs backward computation.
I1204 04:10:04.999821 1969066752 net.cpp:226] conv1 needs backward computation.
I1204 04:10:04.999825 1969066752 net.cpp:228] data does not need backward computation.
I1204 04:10:04.999828 1969066752 net.cpp:270] This network produces output loss
I1204 04:10:04.999862 1969066752 net.cpp:283] Network initialization done.
I1204 04:10:04.999955 1969066752 solver.cpp:59] Solver scaffolding done.
I1204 04:10:05.000012 1969066752 caffe.cpp:212] Starting Optimization
I1204 04:10:05.000026 1969066752 solver.cpp:287] Solving net
I1204 04:10:05.000051 1969066752 solver.cpp:288] Learning Rate Policy: step
I1204 04:10:05.007684 1969066752 solver.cpp:340] Iteration 0, Testing net (#0)
I1204 04:10:07.500277 1969066752 solver.cpp:408]     Test net output #0: loss = 0.260291 (* 1 = 0.260291 loss)
I1204 04:10:34.715260 1969066752 solver.cpp:236] Iteration 0, loss = 0.267981
I1204 04:10:34.715308 1969066752 solver.cpp:252]     Train net output #0: loss = 0.267981 (* 1 = 0.267981 loss)
I1204 04:10:34.715332 1969066752 sgd_solver.cpp:106] Iteration 0, lr = 0.001
I1204 04:10:34.720564 1969066752 solver.cpp:340] Iteration 1, Testing net (#0)
I1204 04:10:37.421115 1969066752 solver.cpp:408]     Test net output #0: loss = 0.245359 (* 1 = 0.245359 loss)
I1204 04:11:03.738864 1969066752 solver.cpp:236] Iteration 1, loss = 0.250055
I1204 04:11:03.738901 1969066752 solver.cpp:252]     Train net output #0: loss = 0.250055 (* 1 = 0.250055 loss)
I1204 04:11:03.738909 1969066752 sgd_solver.cpp:106] Iteration 1, lr = 0.001
I1204 04:11:03.746791 1969066752 solver.cpp:340] Iteration 2, Testing net (#0)
I1204 04:11:06.458186 1969066752 solver.cpp:408]     Test net output #0: loss = 0.252132 (* 1 = 0.252132 loss)
I1204 04:11:34.820169 1969066752 solver.cpp:236] Iteration 2, loss = 0.249862
I1204 04:11:34.820217 1969066752 solver.cpp:252]     Train net output #0: loss = 0.249862 (* 1 = 0.249862 loss)
I1204 04:11:34.820230 1969066752 sgd_solver.cpp:106] Iteration 2, lr = 0.001
I1204 04:11:34.827350 1969066752 solver.cpp:340] Iteration 3, Testing net (#0)
I1204 04:11:37.661497 1969066752 solver.cpp:408]     Test net output #0: loss = 0.237314 (* 1 = 0.237314 loss)
I1204 04:12:05.855695 1969066752 solver.cpp:236] Iteration 3, loss = 0.241053
I1204 04:12:05.855731 1969066752 solver.cpp:252]     Train net output #0: loss = 0.241053 (* 1 = 0.241053 loss)
I1204 04:12:05.855737 1969066752 sgd_solver.cpp:106] Iteration 3, lr = 0.001
I1204 04:12:05.864439 1969066752 solver.cpp:340] Iteration 4, Testing net (#0)
I1204 04:12:08.289422 1969066752 solver.cpp:408]     Test net output #0: loss = 0.242995 (* 1 = 0.242995 loss)
I1204 04:12:35.407670 1969066752 solver.cpp:236] Iteration 4, loss = 0.242811
I1204 04:12:35.407706 1969066752 solver.cpp:252]     Train net output #0: loss = 0.242811 (* 1 = 0.242811 loss)
I1204 04:12:35.407713 1969066752 sgd_solver.cpp:106] Iteration 4, lr = 0.001
I1204 04:12:35.412874 1969066752 solver.cpp:461] Snapshotting to binary proto file weights_iter_5.caffemodel
I1204 04:12:35.480162 1969066752 sgd_solver.cpp:269] Snapshotting solver state to binary proto file weights_iter_5.solverstate
I1204 04:12:35.523910 1969066752 solver.cpp:340] Iteration 5, Testing net (#0)
I1204 04:12:38.234944 1969066752 solver.cpp:408]     Test net output #0: loss = 0.230228 (* 1 = 0.230228 loss)
I1204 04:13:05.558212 1969066752 solver.cpp:236] Iteration 5, loss = 0.242919
I1204 04:13:05.558257 1969066752 solver.cpp:252]     Train net output #0: loss = 0.242919 (* 1 = 0.242919 loss)
I1204 04:13:05.558265 1969066752 sgd_solver.cpp:106] Iteration 5, lr = 0.001
I1204 04:13:05.563616 1969066752 solver.cpp:340] Iteration 6, Testing net (#0)
I1204 04:13:08.130408 1969066752 solver.cpp:408]     Test net output #0: loss = 0.236483 (* 1 = 0.236483 loss)
I1204 04:13:35.388653 1969066752 solver.cpp:236] Iteration 6, loss = 0.234788
I1204 04:13:35.388689 1969066752 solver.cpp:252]     Train net output #0: loss = 0.234788 (* 1 = 0.234788 loss)
I1204 04:13:35.388697 1969066752 sgd_solver.cpp:106] Iteration 6, lr = 0.001
I1204 04:13:35.393568 1969066752 solver.cpp:340] Iteration 7, Testing net (#0)
I1204 04:13:37.927083 1969066752 solver.cpp:408]     Test net output #0: loss = 0.234227 (* 1 = 0.234227 loss)
I1204 04:14:04.398313 1969066752 solver.cpp:236] Iteration 7, loss = 0.241217
I1204 04:14:04.398349 1969066752 solver.cpp:252]     Train net output #0: loss = 0.241217 (* 1 = 0.241217 loss)
I1204 04:14:04.398355 1969066752 sgd_solver.cpp:106] Iteration 7, lr = 0.001
I1204 04:14:04.403489 1969066752 solver.cpp:340] Iteration 8, Testing net (#0)
I1204 04:14:06.961913 1969066752 solver.cpp:408]     Test net output #0: loss = 0.226917 (* 1 = 0.226917 loss)
